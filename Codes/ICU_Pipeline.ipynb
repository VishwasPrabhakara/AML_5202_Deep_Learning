{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_hN0a9Rem7K"
      },
      "source": [
        "## Load modules\n",
        "\n",
        "# Standard modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Preprocessing modules\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler,\\\n",
        " OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
        "\n",
        "# Train-test split module\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Classifier modules\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Regression modules\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Model selection modules\n",
        "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, GridSearchCV\n",
        "\n",
        "# Pipeline module\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Imputation modules\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer, IterativeImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_selector as selector\n",
        "\n",
        "# Performance metric modules\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Plotting modules\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (4.0, 4.0) # set default size of plots\n",
        "\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "# Module for categorical variables\n",
        "from pandas.api.types import CategoricalDtype\n",
        "\n",
        "# Modules for building custom encoders and transformers\n",
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPo9arBOE-JN"
      },
      "source": [
        "## Mount Google drive folder if running in Colab\n",
        "if('google.colab' in sys.modules):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount = True)\n",
        "    # Change path below starting from /content/drive/MyDrive/Colab Notebooks/\n",
        "    # depending on how data is organized inside your Colab Notebooks folder in\n",
        "    # Google Drive\n",
        "    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/MSIS Coursework/EvenSem2024MAHE'\n",
        "    DATA_DIR = DIR+'/Data/'\n",
        "else:\n",
        "    DATA_DIR = 'Data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dlxWVPXHHhs"
      },
      "source": [
        "## Load ICU Data\n",
        "file = DATA_DIR+'ICU_filtered.csv'\n",
        "dfICU = pd.read_csv(file, sep = ',', header = 0, index_col = 0)\n",
        "\n",
        "print('ICU dataset')\n",
        "print('-----------')\n",
        "print('Initial number of samples = %d'%(dfICU.shape[0]))\n",
        "print('Initial number of features = %d\\n'%(dfICU.shape[1]))\n",
        "dfICU.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfgtJWDRB8NH"
      },
      "source": [
        "## Plot percentage of missing values (NaNs) for each feature\n",
        "cutoff = 30 # we will remove features missing in more than 20% of the samples\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "percent_missing = (dfICU.isna().sum() / dfICU.shape[0]) * 100\n",
        "percent_missing.plot(kind = 'bar', color = cm.rainbow(np.linspace(0, 1, 2))[(percent_missing <= cutoff).values.astype(int)])\n",
        "plt.plot(np.arange(dfICU.shape[1]), np.repeat(cutoff, dfICU.shape[1]), 'g--')\n",
        "fig.suptitle('Percentage Missing Values Across All Features', fontsize = 12)\n",
        "plt.xlabel('Feature', fontsize = 12)\n",
        "plt.ylabel('% Missing Values', fontsize = 12);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY3RGJZYH129"
      },
      "source": [
        "## Wrangle the dataframe\n",
        "# Retain features with <= cutoff percentage missing values\n",
        "dfICU = dfICU.loc[:, dfICU.columns[percent_missing <= cutoff]]\n",
        "\n",
        "# Collate different one-hot-encoded ICU-type columns into a single column called ICU\n",
        "dfICU.loc[dfICU['CCU'] == 1, 'ICU'] = 1\n",
        "dfICU.loc[dfICU['CSRU'] == 1, 'ICU'] = 2\n",
        "dfICU.loc[dfICU['SICU'] == 1, 'ICU'] = 3\n",
        "dfICU.loc[(dfICU['CCU'] == 0 ) & (dfICU['CSRU'] == 0) & (dfICU['SICU'] == 0), 'ICU'] = 4\n",
        "dfICU.drop(['CCU', 'CSRU', 'SICU'], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lists of ordinal, categorical, and continuous features\n",
        "ordinal_features = ['GCS_first']\n",
        "categorical_features = [ 'Gender', 'ICU', 'MechVent']\n",
        "continuous_features = dfICU.columns[~dfICU.columns.isin(ordinal_features + categorical_features)].to_list()\n",
        "dfICU.head(5)"
      ],
      "metadata": {
        "id": "rDeLtas8CtcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Custom ordinal encoder\n",
        "class CustomOrdinalEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, ordinal_cols_dict: dict):\n",
        "        self.ordinal_cols_dict = ordinal_cols_dict\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y = None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X: pd.DataFrame, y = None):\n",
        "        for col, order in self.ordinal_cols_dict.items():\n",
        "            cat_type = CategoricalDtype(categories = self.ordinal_cols_dict[col], ordered = True)\n",
        "            X[col] = X[col].astype(cat_type).factorize(sort = True)[0]\n",
        "            X[col] = X[col].astype(CategoricalDtype(ordered = True))\n",
        "            X[col] = X[col].replace(-1, np.nan)\n",
        "        return X\n",
        "\n",
        "    def fit_transform(self, X: pd.DataFrame, y = None):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)"
      ],
      "metadata": {
        "id": "ufcJScjAhf3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Custom categorical encoder\n",
        "class CustomCategoricalEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, categorical_cols: list):\n",
        "        self.categorical_cols = categorical_cols\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y = None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X: pd.DataFrame, y = None):\n",
        "        for col in self.categorical_cols:\n",
        "            cat_type = 'category'\n",
        "            X[col] = X[col].astype(cat_type).factorize()[0]\n",
        "            X[col] = X[col].astype('category')\n",
        "            X[col] = X[col].replace(-1, np.nan)\n",
        "        return X\n",
        "\n",
        "    def fit_transform(self, X: pd.DataFrame, y = None):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)"
      ],
      "metadata": {
        "id": "dVsEeOfVnnc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Build preprocessing pipeline for ordinal, categorical, and continuous features\n",
        "# Define preprocessing pipeline for ordinal features\n",
        "# Dictionary for ordinal features\n",
        "ordinal_cols_dict = {\n",
        "    'GCS_first': np.arange(np.max(dfICU['GCS_first']), np.min(dfICU['GCS_first'])-1, -1)\n",
        "    }\n",
        "ordinal_transformer = Pipeline(steps = [('customordenc', CustomOrdinalEncoder(ordinal_cols_dict)),\n",
        "    ('imputer', IterativeImputer(estimator = RandomForestClassifier(n_estimators = 3),\n",
        "                                 initial_strategy = 'most_frequent',\n",
        "                                 missing_values = np.nan,\n",
        "                                 max_iter = 10,\n",
        "                                 random_state = 0))])\n",
        "\n",
        "# Define preprocessing pipeline for categorical features\n",
        "categorical_transformer = Pipeline(steps = [('customcatenc', CustomCategoricalEncoder(categorical_features)),\n",
        "    ('imputer', IterativeImputer(estimator = RandomForestClassifier(n_estimators = 3),\n",
        "                                 initial_strategy = 'most_frequent',\n",
        "                                 missing_values = np.nan,\n",
        "                                 max_iter = 10,\n",
        "                                 random_state = 0))])\n",
        "\n",
        "# Define preprocessing pipeline for continuous features\n",
        "numeric_transformer = Pipeline(steps = [('imputer', IterativeImputer(estimator = RandomForestRegressor(n_estimators = 3),\n",
        "                                                                     initial_strategy = 'median',\n",
        "                                                                     missing_values = np.nan,\n",
        "                                                                     max_iter = 10,\n",
        "                                                                     random_state = 0)),\n",
        "                                        ('scaler', RobustScaler())])\n",
        "\n",
        "# Create preprocessor object for all features\n",
        "preprocessor = ColumnTransformer(transformers = [('ord', ordinal_transformer, ordinal_features),\n",
        "                                                 ('cat', categorical_transformer, categorical_features),\n",
        "                                                 ('num', numeric_transformer, continuous_features)\n",
        "                                                 ])\n",
        "\n",
        "# Fit and transform using the preprocessor\n",
        "dfICU = pd.DataFrame(preprocessor.fit_transform(dfICU))"
      ],
      "metadata": {
        "id": "w9Ca7uPSi2FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfICU"
      ],
      "metadata": {
        "id": "9HIn1YMJsXaA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}