{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"AtKh7DZWkCMa"},"source":["## Load Libraries\n","import pandas as pd\n","import numpy as np\n","import sys\n","from scipy import linalg\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","plt.style.use('seaborn-whitegrid')\n","%matplotlib inline\n","\n","from PIL import Image"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Mount the Google Drive folder, if needed, for accessing data\n","if('google.colab' in sys.modules):\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount = True)\n","    # Change path below starting from /content/drive/MyDrive/Colab Notebooks/\n","    # depending on how data is organized inside your Colab Notebooks folder in\n","    # Google Drive\n","    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/MSIS Coursework/OddSem2023MAHE'\n","    DATA_DIR = DIR+'/Data/'\n","else:\n","    DATA_DIR = 'Data/'"],"metadata":{"id":"XnF_-coZBx-O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","**The following user-defined function will be used for component-plotting vectors**\n","\n","---"],"metadata":{"id":"yPgSJvXzCp1B"}},{"cell_type":"code","source":["def plotveccomp(x, name = ' ', color = 'black', marker = '*', axis = None):\n","  ax = axis\n","  component_index = range(0, len(x))\n","  ax.plot(component_index, x, color = color, marker = marker)\n","  ax.plot(component_index, [np.mean(x)]*len(x), linewidth = 1, linestyle = 'dashed', color ='blue')\n","  ax.plot(component_index, [np.mean(x) - np.std(x)]*len(x), linewidth = 1, linestyle = 'dashed', color ='red')\n","  ax.plot(component_index, [np.mean(x) + np.std(x)]*len(x), linewidth = 1, linestyle = 'dashed', color ='red')\n","  ax.set_xlabel('Index')\n","  ax.set_ylabel('Value')\n","  ax.set_title('Component plot of '+name)"],"metadata":{"id":"434vqQQ7Cql8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","**Read hourly temperature data**\n","\n","---"],"metadata":{"id":"mCley4VXG15Q"}},{"cell_type":"code","source":["## Read hourly temperature data for multiple cities\n","FILE = DATA_DIR + 'temperature.csv'\n","df_temp = pd.read_csv(FILE, sep = \",\", header = 0, skiprows = [1])\n","df_temp['datetime'] = pd.to_datetime(df_temp['datetime'], format='%Y-%m-%d %H:%M:%S')\n","df_temp = df_temp.set_index('datetime')\n","df_temp.head()"],"metadata":{"id":"1afAPpuUCvzZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","**Extract daily temperature vector for San Francisco**\n","\n","---"],"metadata":{"id":"KrRZLp52C07b"}},{"cell_type":"code","source":["# Temperature vector for San Francisco for 2012-10-02\n","t1 = df_temp.iloc[df_temp.index.get_loc('2012-10-02'), df_temp.columns.get_loc('San Francisco')].values\n","print(t1)\n","\n","# Temperature vector for San Francisco for 2012-12-02\n","t2 = df_temp.iloc[df_temp.index.get_loc('2012-12-02'), df_temp.columns.get_loc('San Francisco')].values\n","print(t2)\n","\n","# Plot temperature vectors for both days\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10,6))\n","fig.tight_layout(pad = 4.0)\n","plotveccomp(t1, 'San Francisco Temperature 2012-10-02', 'black', '*', ax1)\n","plotveccomp(t2, 'San Francisco Temperature 2012-12-02', 'black', '*', ax2)"],"metadata":{"id":"A00g-VBwC3u-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","**Wikipedia articles as vectors**\n","\n","---"],"metadata":{"id":"GJHWSaERHMIb"}},{"cell_type":"code","source":["## Install the wikipedia package\n","!pip install wikipedia\n","\n","# Load the Wikipedia package\n","import wikipedia as wiki"],"metadata":{"id":"w8JKgRs8HMvB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","**Extract Wikipedia content for 3 topics: Jungle Book, Harry Potter, Tarzan**\n","\n","---"],"metadata":{"id":"nPD3JY6VHbY4"}},{"cell_type":"code","source":["# Extract Wikipedia content for 3 topics\n","a = wiki.page('jungle book', auto_suggest = False)\n","b = wiki.page('Harry Potter', auto_suggest = False)\n","c = wiki.page('Tarzan', auto_suggest = False)\n","# Print number of words in each article\n","print(len(a.content.split()))\n","print(len(b.content.split()))\n","print(len(c.content.split()))"],"metadata":{"id":"POzEmkN6HViZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(a.content)"],"metadata":{"id":"Bt_PiUT-HeTh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","**Import text-to-vector vectorizers**\n","\n","---"],"metadata":{"id":"vcn26bq8He_9"}},{"cell_type":"code","source":["## Import text-to-vector vectorizers\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"],"metadata":{"id":"ov30atC5Hhrd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","**Vectorize the articles**\n","\n","---"],"metadata":{"id":"TvwFmQ4pHlJK"}},{"cell_type":"code","source":["# Create a vectorizer object\n","cv = CountVectorizer()\n","tfidfv = TfidfVectorizer()\n","A = np.asarray(tfidfv.fit_transform([a.content, b.content, c.content]).todense())\n","#feature_words = cv.get_feature_names_out()\n","print(A.shape)\n","#print(feature_words)\n","print(A[0])"],"metadata":{"id":"uuLfQZSMHoxU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","The patient data matrix:\n","\n","![Patient dataset](https://bl3302files.storage.live.com/y4mTMCQdiTnIFj1IALg09CRz7pPWl0g4HpigAPbwyMmF0QNliGAgK3aEsBESo0BNFCy-0-kR6pllskO1DPVt2-76bYsQaACRWhkOebqJ545BbtWcGr1CJG72BZJPrYbQDWNAC0h1EHhpewBlORT_xtahEu-bite73OVi-4CzGeQf6GDw11H6kn72VocdC2bLAsJ?width=256&height=167&cropmode=none)\n","\n","---\n","\n","**Addition and subtraction of vectors, scalar multiplication (apply operation componentwise)**\n","\n","![Vector addition](https://bl3302files.storage.live.com/y4mMlnDRWzIoNKWynOZFhzhFNDlReoFxf7XwSeFwNWW8f1lu5ssj_SvgMAEN9BWiQ2F-meER7rD2an2n2tfDoWffBHE8aD_WBsL0LAbHxnIpZtZu6hNJAvZ88m746S_ktA9-h-oo108AQjkXQHkYrgJ5AUCpvKB2dipeNG1VfIK_38Q8fsq6OKD43adplgy0H1k?width=200&height=80&cropmode=none)\n","\n","![Vector subtraction](https://bl3302files.storage.live.com/y4mnQkNUONVVKJJ6dCEqV9lEuP360lE0yRumSIgl9LaQH_qBqjgI9wvUd64xJ-UNIjR7wJXZyaXZ_kf1_gAB9sXjMWaMxWhSnX6zcyvVtTrCDeO1MNWzj3A1YqI5YLALK-CGCSMurNV938QLH3C2u1-BE8_addFYSeO7DmCKz5TdWGf7qtC8M9rRN26RMqpk8iu?width=200&height=80&cropmode=none)\n","\n","![Scalar-vector multiplication](https://bl3302files.storage.live.com/y4mYNwLMmuKRl3sNDSo0yyXYs0KFw1LBnQCU6nAgSawanlGNgLq7Bd93DQ0ojamRpGLx_PZvnsSG-6K-3TsdDctw5sm-QxnWUHSTJGalDR4JmUp27_Hf3ESAQukZ1Jk5G16ykO7H3AKmLSQxE4vVIAtMFbCnyxtsQEfpyb_SK5jIjVtjl7yoFcBDzsRDGzo5cZM?width=200&height=80&cropmode=none)\n","\n","---"],"metadata":{"id":"HWJOsN5EJbMs"}},{"cell_type":"code","source":["X = np.array(pd.DataFrame({'HR' : [76, 74, 72, 78],\n","                   'BP' : [126, 120, 118, 136],\n","                   'Temp': [38.0, 38.0, 37.5, 37.0]}))\n","\n","print(X)\n","\n","# Vector addition\n","print(X[1, :]+ X[2, :])\n","\n","# Vector subtraction\n","print(X[1, :]- X[2, :])\n","\n","# Scalar-vector multiplication\n","print((9/5)*X[:, 2]+32)\n","\n","# Average patient\n","print((1/4)*(X[0, :] + X[1, :] + X[2, :] + X[3, :]))"],"metadata":{"id":"sJQIXpJ3IFIm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# How are the elements of the patient data matrix structured?\n","print(X[0])\n","print(X[1])\n","print(X[2])\n","print(X[3])"],"metadata":{"id":"036wgxuQIwjA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","**Load a color image as 3D tensor**\n","\n","<img src = 'https://drive.google.com/uc?id=1-kENYuqShwKAVI3oqryeMA_aXemoXmIW'>\n","\n","---"],"metadata":{"id":"2xQNnnZYC_dD"}},{"cell_type":"code","source":["## Read image\n","FILENAME = DATA_DIR + 'lion.jpg'\n","# Read image\n","img = Image.open(FILENAME)\n","# Convert image to gray scale\n","imggray = img.convert('L')\n","# Convert image into a 3D numpy array (a.k.a. a matrix)\n","X = np.array(img)\n","print(X.shape)\n","# Convert image matrix into a vector\n","x = X.flatten()\n","print(x.shape)"],"metadata":{"id":"O7I-WUkdC_Ff"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","A tensor of dimension 3 corresponding to 4 time stamps, 3 samples, 2 features (HR and BP)\n","\n","---"],"metadata":{"id":"PSV91C_8HADU"}},{"cell_type":"code","source":["# Create a tensor of dimesion 3\n","# 4 time stamps, 3 samples, 2 features\n","T = np.array([[[74, 128], [79, 116], [71, 116]],\n","              [[78, 118], [82, 124], [72, 128]],\n","              [[84, 138], [84, 130], [74, 120]],\n","              [[82, 126], [76, 156], [82, 132]]])\n","print(T.shape)\n","print(T)\n","print(T[0])\n","print(T[0][0])"],"metadata":{"id":"gVvQsMiWHBIF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Reshape tensor to represent (patients, timestamps, features). That is, the features become the last index.\n","\n","---"],"metadata":{"id":"NoOXdDdrL3hE"}},{"cell_type":"code","source":["T_reshaped = T.transpose(1, 0, 2)\n","print(T_reshaped)"],"metadata":{"id":"op3qwis6L6ou"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","$l_2$ norm or the geometric length of a vector denoted as $\\lVert a\\rVert$ tells us how long a vector is. In 2-dimensions, $\\lVert a\\rVert_2 = \\sqrt{a_1^2+a_2^2}$ and in $n$-dimensions, $\\lVert a\\rVert_2 = \\sqrt{a_1^2+a_2^2+\\cdots+a_n^2}.$\n","\n","---"],"metadata":{"id":"wLSjoeMBKbvG"}},{"cell_type":"code","source":["a = np.array([1, 2, 3])\n","np.linalg.norm(a)"],"metadata":{"id":"qgLXcYlJKez6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Dot product between two vectors is simply a pairwise-multiplication followed by a summation: for example, $a\\cdot b = a_1\\times b_2+a_2\\times b_2+\\cdots+a_n\\times b_n.$\n","\n","---"],"metadata":{"id":"c0xn5Ov-M8E4"}},{"cell_type":"code","source":["a = np.array([1, 2, 3])\n","b = np.array([4, 5, 6])\n","np.dot(a, b)"],"metadata":{"id":"_uScN_AdNvyw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Cauchy-Schwarz inequality $-1\\leq\\frac{a\\cdot b}{\\lVert a\\rVert\\lVert b\\rVert}\\leq1.$\n","\n","---"],"metadata":{"id":"C63FDdDfEtCS"}},{"cell_type":"code","source":["np.dot(a, b) / (np.linalg.norm(a)*np.linalg.norm(b))"],"metadata":{"id":"t1PEF_tuEvKp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","**Calculate Euclidean and cosine dissimilarity between the Wikipedia articles**\n","\n","---"],"metadata":{"id":"k-dtxOmiGssZ"}},{"cell_type":"code","source":["# Lambda functions for calculating distances\n","d_E = lambda a, b: np.linalg.norm(a-b) # Euclidean distance\n","d_cos = lambda a, b: 1-(np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b)))\n","\n","# Euclidean dissimilarity\n","print(d_E(A[0], A[1])) # between Jungle Book and Harry Potter\n","print(d_E(A[0], A[2])) # between Jungle Book and Tarzan\n","\n","# Cosine dissimilarity\n","print(d_cos(A[0], A[1])) # between Jungle Book and Harry Potter\n","print(d_cos(A[0], A[2])) # between Jungle Book and Tarzan"],"metadata":{"id":"lrbdrYMTGtT0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Matrix-vector product is simply a sequence of dot products of the rows of matrix (seen as vectors) with the vector\n","\n","---"],"metadata":{"id":"MJ24hd7REyG2"}},{"cell_type":"code","source":["A = np.array([[1,2,-1,-1], [2,4,-2,3], [-1,1,-2,4]])\n","x = np.array([-1, 1, 1, 0])\n","print(A)\n","print(A.shape)\n","print(A[0])\n","print(A[1])\n","print(A[2])\n","print(A[0].shape)\n","print(x)\n","print(np.dot(A, x))"],"metadata":{"id":"22Yxw-hGEzzj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Linear combination of columns of the matrix using the components of the vector is equivalent to the dot product of the rows of the matrix with the vector\n","\n","----"],"metadata":{"id":"lxQjnPUpK4UX"}},{"cell_type":"code","source":["print(A)\n","print(x)\n","# Dot product of rows of A with x\n","print(np.dot(A, x))\n","# Linear combination of columns of A using components of x\n","print(x[0]*A[:, 0] + x[1]*A[:, 1] + x[2]*A[:, 2] + x[3]*A[:, 3])\n","np.sum(x[range(4)] * A[:, range(4)], axis = 1) # faster"],"metadata":{"id":"56_Zybo7K5SR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Matrix-matrix product using the patient data matrix:\n","\n","![Patient dataset](https://bl3302files.storage.live.com/y4mTMCQdiTnIFj1IALg09CRz7pPWl0g4HpigAPbwyMmF0QNliGAgK3aEsBESo0BNFCy-0-kR6pllskO1DPVt2-76bYsQaACRWhkOebqJ545BbtWcGr1CJG72BZJPrYbQDWNAC0h1EHhpewBlORT_xtahEu-bite73OVi-4CzGeQf6GDw11H6kn72VocdC2bLAsJ?width=256&height=167&cropmode=none)\n","\n","---"],"metadata":{"id":"N6ExSeHaLRi8"}},{"cell_type":"code","source":["W = np.array([[0.8, 0.1], [0.1, 0.4], [0.1, 0.4]])\n","X = np.array(pd.DataFrame({'HR' : [76, 74, 72, 78],\n","                   'BP' : [126, 120, 118, 136],\n","                   'Temp': [38.0, 38.0, 37.5, 37.0]}))\n","print(X)\n","print(W)\n","print(np.dot(X, W))"],"metadata":{"id":"nZqPZ2KGLbQ3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Tensor-vector product is simply a sequence of matrix-vector products which in turn are a sequence of dot products of vectors\n","\n","---"],"metadata":{"id":"Xw_Dvx0AFKIX"}},{"cell_type":"code","source":["x = np.array([1, 0])\n","print(T)\n","print(x)\n","print(T.shape)\n","print(x.shape)\n","print(np.dot(T, x))"],"metadata":{"id":"5nj6X_B2FKqV"},"execution_count":null,"outputs":[]}]}