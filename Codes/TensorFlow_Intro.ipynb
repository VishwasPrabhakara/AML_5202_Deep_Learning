{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "From https://www.tensorflow.org/guide/basics\n",
        "\n",
        "TensorFlow (TF) is an end-to-end platform for machine learning. It supports the following:\n",
        "\n",
        "1. Multidimensional-array based numeric computation (similar to NumPy.)\n",
        "2. GPU and distributed processing\n",
        "3. Automatic differentiation\n",
        "4. Model construction, training, and export\n",
        "5. And more\n",
        "\n",
        "---\n",
        "\n",
        "Some important points about TF.\n",
        "\n",
        "* TensorFlow was developed by the Google Brain team for internal use at Google. Then, it was made open source in November 2015.\n",
        "* Keras is an API (application programming interface) for deep learning calculations. API means that Keras defines a specific interface to write codes.\n",
        "* Keras was written in Python.\n",
        "* Keras has multiple backends (libraries that are\n",
        "responsible for doing the actual calculations): TensorFlow,\n",
        "CNTK, Theano.\n",
        "* Keras is focused on easy and fast prototyping, through\n",
        "user friendliness, modularity, and extensibility.\n",
        "* Although TF can be used as a backend for Keras, it is\n",
        "recommended to use tf.keras, which is the implementation\n",
        "of Keras in TF.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ibsqZFNDOtcL"
      },
      "id": "ibsqZFNDOtcL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Load essential libraries**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "CrW3wGfQN2KV"
      },
      "id": "CrW3wGfQN2KV"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "valued-lodging",
      "metadata": {
        "id": "valued-lodging",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cafbab3f-2286-41ec-ad11-f09759cbb488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-29be9d77aeab>:3: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
            "  plt.style.use('seaborn-whitegrid')\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Check TensorFlow version**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "CZmMj92lN6Yc"
      },
      "id": "CZmMj92lN6Yc"
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "B2VpALYvOBoG"
      },
      "id": "B2VpALYvOBoG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Introduction to tensors from https://www.tensorflow.org/guide/tensor\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "V6MJcE8mQuxG"
      },
      "id": "V6MJcE8mQuxG"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4CbC5yVsQyth"
      },
      "id": "4CbC5yVsQyth",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Introduction to variables from https://www.tensorflow.org/guide/variable\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "CHCPJZG6QzKr"
      },
      "id": "CHCPJZG6QzKr"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gGjQqL8gQ8rk"
      },
      "id": "gGjQqL8gQ8rk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Automatic differentiation using TF (https://www.tensorflow.org/guide/autodiff)\n",
        "\n",
        "Example: calculate the sensitivity of $L(w) = 4w+w^3$ w.r.t. the input $w$ at $w=1.$\n",
        "\n",
        "Sensitivity $\\nabla_wL = 4+3w^2,$ which at $w=1$ is equal to $4+3\\times1^2=7.$\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6U1TokFxQ_w2"
      },
      "id": "6U1TokFxQ_w2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "banner-guatemala",
      "metadata": {
        "id": "banner-guatemala"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "better-restoration",
      "metadata": {
        "id": "better-restoration"
      },
      "source": [
        "---\n",
        "\n",
        "Example: calculate the sensitivity of $L(w_1,w_2) = w_1+w_2^2$ w.r.t. the inputs $w_1, w_2$ at $w_1=1, w_2=2.$\n",
        "\n",
        "Setting $\\mathbf{w} = \\begin{bmatrix}w_1\\\\w_2\\end{bmatrix},$ sensitivity $\\nabla_\\mathbf{w}L= \\begin{bmatrix}\\nabla_{w_1}(w_1+w_2^2)\\\\\\nabla_{w_2}(w_1+w_2^2)\\end{bmatrix} = \\begin{bmatrix}1\\\\2w_2\\end{bmatrix},$\n",
        "\n",
        " which at $w_1=1,w_2=2$ is equal to $\\begin{bmatrix}1\\\\4\\end{bmatrix}.$\n",
        "\n",
        " ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "continuous-protocol",
      "metadata": {
        "id": "continuous-protocol"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "alert-prairie",
      "metadata": {
        "id": "alert-prairie"
      },
      "source": [
        "---\n",
        "\n",
        "In TF, we can control which input is considered an independent variable versus a constant value.\n",
        "\n",
        "`gradient` will return `None` when the input is not a `tf.Variable`.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ordered-midwest",
      "metadata": {
        "id": "ordered-midwest"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "statewide-voluntary",
      "metadata": {
        "id": "statewide-voluntary"
      },
      "source": [
        "---\n",
        "\n",
        "A `tf.Tensor` can be used as a variable using the `watch` function.\n",
        "\n",
        "For example, consider calculating the sensitivity of $L(w) = w^4$ at $w=-3.$\n",
        "\n",
        "The sensitivity is $\\nabla_wL = 4w^3,$ which at $w=-3$ is equal to $4\\times(-3)^3 = -108.$\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stable-macro",
      "metadata": {
        "id": "stable-macro"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "contrary-hollywood",
      "metadata": {
        "id": "contrary-hollywood"
      },
      "source": [
        "---\n",
        "\n",
        "We can use multiple tensor variables as input. This just means we calculate the sensitivity w.r.t. all the variables in the tensor.\n",
        "\n",
        "For example, consider calculating the sensitivity of $L(w) = w[0]^2+w[1]^2$ at $w[0] = 1, w[1] = -3.$\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "handled-mexico",
      "metadata": {
        "id": "handled-mexico"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "athletic-carnival",
      "metadata": {
        "id": "athletic-carnival"
      },
      "source": [
        "---\n",
        "\n",
        "When `g.gradient` is called with a tensor dependent variable (tensor target), it returns the sum of the sensitivities for each component of the target variable.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fatal-calibration",
      "metadata": {
        "id": "fatal-calibration"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "latter-generic",
      "metadata": {
        "id": "latter-generic"
      },
      "source": [
        "---\n",
        "\n",
        "By default, when we call `g.gradient`, all resources required to compute the gradient are released. This allows saving memory. However, there are cases when we want to call `g.gradient` several times, for example, to differentiate different chained functions. In that case, we must use the option `persistent=True`.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "conscious-twins",
      "metadata": {
        "id": "conscious-twins"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "alternate-tournament",
      "metadata": {
        "id": "alternate-tournament"
      },
      "source": [
        "---\n",
        "\n",
        "We can easily calculate sensitivies of functions and plot them.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "difficult-documentary",
      "metadata": {
        "id": "difficult-documentary"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}