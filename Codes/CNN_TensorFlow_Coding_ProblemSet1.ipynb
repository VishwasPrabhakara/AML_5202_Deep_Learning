{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dEgRpy3952M"
      },
      "outputs": [],
      "source": [
        "## Load libraries\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9W_1_v_6yq7"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Mount Google drive\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Oxh-edx53BBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Mount Google drive folder if running in Colab\n",
        "if('google.colab' in sys.modules):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount = True)\n",
        "    # Change path below starting from /content/drive/MyDrive/Colab Notebooks/\n",
        "    # depending on how data is organized inside your Colab Notebooks folder in\n",
        "    # Google Drive\n",
        "    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/MSIS Coursework/EvenSem2024MAHE'\n",
        "    DATA_DIR = DIR+'/Data/'\n",
        "else:\n",
        "    DATA_DIR = 'Data/'"
      ],
      "metadata": {
        "id": "KBB8g8WC3DM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Load image**\n",
        "\n",
        "<img src = 'https://drive.google.com/uc?id=1ZpG6qRKG-Ry9poVjvgJTtryOiFNwPWSI' width = '400'>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "nOwV9mxbRzRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Read image\n",
        "FILENAME = DATA_DIR + 'lion_grayscale.jpg'\n",
        "# Read image\n",
        "img = Image.open(FILENAME)\n",
        "plt.imshow(img, cmap = 'gray')\n",
        "X = np.array(img)/1.0\n",
        "X.shape"
      ],
      "metadata": {
        "id": "W9x-G6XUSGnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Define filters (also kernels because channel depth is 1 for a gray scale image)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "RfqKX5VTSial"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W_smoothen = np.array([[\n",
        "    [1/9, 1/9, 1/9],\n",
        "    [1/9, 1/9, 1/9],\n",
        "    [1/9, 1/9, 1/9]\n",
        "    ]])\n",
        "print(W_smoothen.shape)\n",
        "W_smoothen = np.transpose(W_smoothen, (1, 2, 0))\n",
        "print(W_smoothen.shape)"
      ],
      "metadata": {
        "id": "vQQUOXC_SjH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_sharpen = np.array([[\n",
        "    [-1, -1, -1],\n",
        "    [-1, 9, -1],\n",
        "    [-1, -1, -1]\n",
        "    ]])\n",
        "print(W_sharpen.shape)\n",
        "W = np.transpose(W_sharpen, (1, 2, 0))\n",
        "print(W_sharpen.shape)"
      ],
      "metadata": {
        "id": "SzVNOqIDlUkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_vertical_edge = np.array([[\n",
        "    [1, 0, -1],\n",
        "    [1, 0, -1],\n",
        "    [1, 0, -1]\n",
        "    ]])\n",
        "print(W_vertical_edge.shape)\n",
        "W_vertical_edge = np.transpose(W_vertical_edge, (1, 2, 0))\n",
        "print(W_vertical_edge.shape)"
      ],
      "metadata": {
        "id": "JGr8JfhBn3us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_horizontal_edge = np.array([[\n",
        "    [1, 1, 1],\n",
        "    [0, 0, 0],\n",
        "    [-1, -1, -1]\n",
        "    ]])\n",
        "print(W_horizontal_edge.shape)\n",
        "W_horizontal_edge = np.transpose(W_horizontal_edge, (1, 2, 0))\n",
        "print(W_horizontal_edge.shape)"
      ],
      "metadata": {
        "id": "Zly6k4yVoz6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_gaussian = np.array([[\n",
        "    [1/16, 2/16, 1/16],\n",
        "    [2/16, 4/16, 2/16],\n",
        "    [1/16, 2/16, 1/16]\n",
        "    ]])\n",
        "print(W_gaussian.shape)\n",
        "W_gaussian = np.transpose(W_gaussian, (1, 2, 0))\n",
        "print(W_gaussian.shape)"
      ],
      "metadata": {
        "id": "jbguz9yHkGWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Define convolution layer and initialize the kernel\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YJmgCp4qTJzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = tf.keras.layers.Conv2D(\n",
        "        filters = 1,\n",
        "        kernel_size = [3, 3],\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        kernel_initializer = tf.constant_initializer(W_vertical_edge)\n",
        "    )"
      ],
      "metadata": {
        "id": "9D0OSO3mTGWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Apply convolution layer and plot resulting output\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "r_BWSvqTTUPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'input shape = {np.expand_dims(X, axis = (0, -1)).shape}')\n",
        "output = layer(np.expand_dims(X, axis = (0, -1)))\n",
        "print(f'output shape = {output.shape}')\n",
        "\n",
        "# Squeeze and plot the output\n",
        "plt.imshow(tf.squeeze(output), cmap = 'gray');"
      ],
      "metadata": {
        "id": "m3j9kOlJTd6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "In the following code segments, you will show that a convolution neuron learns about an input sample\n",
        "1. channel-by-channel;\n",
        "2. locally through the convolution operation.\n",
        "\n",
        "The raw scores map $\\mathbf{WX}$ calcuated by a single convolution neuron for a 3-channel input $\\mathbf{X}$ is equal to $$\\underbrace{\\mathbf{W}_1}_{\\text{kernel for channel-1}}\\circledast\\underbrace{\\mathbf{X}_1}_\\text{channel-1}+\\underbrace{\\mathbf{W}_2}_{\\text{kernel for channel-2}}\\circledast\\underbrace{\\mathbf{X}_2}_\\text{channel-2}+\\underbrace{\\mathbf{W}_3}_{\\text{kernel for channel-3}}\\circledast\\underbrace{\\mathbf{X}_3}_\\text{channel-3} +\\underbrace{\\mathbf{b}}_\\text{bias of appropriate shape}.$$\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Z9kkJCG7CYYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An input image of shape 3 x 5 x 5 (channels x height x width)\n",
        "X = tf.constant([\n",
        "    [[0., 2, 0, 2, 1],\n",
        "     [1, 1, 2, 0, 2],\n",
        "     [0, 1, 0, 0, 1],\n",
        "     [0, 2, 1, 2, 0],\n",
        "     [2, 0, 0, 0, 2]\n",
        "     ],\n",
        "    [[2, 1, 0, 0, 1],\n",
        "     [2, 2, 0, 2, 1],\n",
        "     [0, 0, 0, 2, 0],\n",
        "     [2, 2, 2, 0, 1],\n",
        "     [0, 0, 1, 0, 2]],\n",
        "    [[1, 2, 0, 0, 2],\n",
        "     [2, 1, 1, 0, 1],\n",
        "     [1, 2, 1, 0, 2],\n",
        "     [0, 2, 1, 0, 1],\n",
        "     [2, 2, 0, 1, 0]]\n",
        "])\n",
        "print(f'Original shape of X with channel as 0th axis = {X.shape}')\n",
        "\n",
        "# Reshape input image into order (height x width x channels)\n",
        "X = tf.transpose(X, (1, 2, 0))\n",
        "print(f'Shape of X with channel as last axis = {X.shape}')\n",
        "\n",
        "# Filter of shape 3 x 3 x 3 (kernels x height x width)\n",
        "W = tf.constant([\n",
        "    [[0., -1., -1],\n",
        "     [0, 0, 0.],\n",
        "     [-1, -1, -1]],\n",
        "    [[1, 0, 1],\n",
        "     [1., -1, -1],\n",
        "     [1., 1., 0.]],\n",
        "    [[1, -1, 0.],\n",
        "     [-1, -1., 1],\n",
        "     [0, 1., -1]]\n",
        "]).numpy()\n",
        "print(f'Shape of filter with kernels as the 0th axis = {W.shape}')\n",
        "\n",
        "# Reshape kernels into order (height x width x kernels)\n",
        "W = tf.transpose(W, (1, 2, 0)).numpy()\n",
        "print(f'Shape of filter with kernels as the last (-1th) axis = {W.shape}')\n",
        "\n",
        "# bias value for the filter\n",
        "b = 1"
      ],
      "metadata": {
        "id": "Emi9P8DgCb4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Calculate raw score map as $$\\underbrace{\\mathbf{W}}_{\\text{kernels for all input channels}}\\mathbf{X}+\\underbrace{\\mathbf{b}}_\\text{bias of appropriate shape}$$ with a single convolution layer corresponding to a filter with 3 kernels and a bias. Use unit padding and stride = 2.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WsF3Q1UGgNHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Define convolution layer\n",
        "layer = tf.keras.layers.Conv2D(\n",
        "        filters = 1,\n",
        "        kernel_size = [3, 3],\n",
        "        strides=(2, 2),\n",
        "        padding = 'same',\n",
        "        kernel_initializer = tf.constant_initializer(W),\n",
        "        bias_initializer = tf.constant_initializer(b)\n",
        "        )\n",
        "# Apply convolution to the input sample to get the raw scores map\n",
        "output = layer(np.expand_dims(X, axis = 0))\n",
        "print(f'Original input shape: {np.expand_dims(X, axis = 0).shape}')\n",
        "print(f'Original output shape: {output.shape}')\n",
        "print(f'Squeezed output shape: {tf.squeeze(output).shape}')\n",
        "print(f'Squeezed output:\\n {tf.squeeze(output)}')"
      ],
      "metadata": {
        "id": "qa6JgsyTga0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Calculate raw scores map $\\mathbf{WX}+\\mathbf{b}$ as $$\\underbrace{\\mathbf{W}_1}_{\\text{kernel for channel-1}}\\circledast\\underbrace{\\mathbf{X}_1}_\\text{channel-1}+\\underbrace{\\mathbf{W}_2}_{\\text{kernel for channel-2}}\\circledast\\underbrace{\\mathbf{X}_2}_\\text{channel-2}+\\underbrace{\\mathbf{W}_3}_{\\text{kernel for channel-3}}\\circledast\\underbrace{\\mathbf{X}_3}_\\text{channel-3} +\\underbrace{\\mathbf{b}}_\\text{bias of appropriate shape}$$ using a depthwise convolution layer corresponding to a filter with 3 kernels and a bias. Use unit padding and stride = 2.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "raMpVpRqpZkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Define depthwise convolution layer\n",
        "layer_depthwise = tf.keras.layers.DepthwiseConv2D(\n",
        "        kernel_size = [3, 3],\n",
        "        strides=(2, 2),\n",
        "        padding = 'same',\n",
        "        depthwise_initializer = tf.constant_initializer(W)\n",
        "    )\n",
        "# Apply depthwise convolution to the input sample and add bias\n",
        "# to get the raw scores map\n",
        "output = layer_depthwise(np.expand_dims(X, axis = 0))\n",
        "\n",
        "print(f'Original input shape: {np.expand_dims(X, axis = 0).shape}')\n",
        "print(f'Original output shape: {output.shape}')\n",
        "\n",
        "print(f'Convolution applied to channel-0 results in: \\n {tf.squeeze(output[:, :, :, 0])}')\n",
        "print(f'Convolution applied to channel-1 results in: \\n {tf.squeeze(output[:, :, :, 1])}')\n",
        "print(f'Convolution applied to channel-2 results in: \\n {tf.squeeze(output[:, :, :, 2])}')\n",
        "\n",
        "# Adding the convolutions across each channel gives the full convolution output\n",
        "# volume which is the raw score map calculated by the neuron.\n",
        "print(f'The full convolution output volume is the sum of all channel convolutions plus the bias:\\n')\n",
        "# Both of the following do the same\n",
        "print(tf.squeeze(output[:, :, :, 0] + output[:, :, :, 1] + output[:, :, :, 2]) + b)\n",
        "print(tf.reduce_sum(tf.squeeze(output), axis = -1) + b)"
      ],
      "metadata": {
        "id": "1N5CmH8pl8os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Calculate raw scores map $\\mathbf{WX}$ as $$\\underbrace{\\mathbf{W}_1}_{\\text{kernel for channel-1}}\\circledast\\underbrace{\\mathbf{X}_1}_\\text{channel-1}+\\underbrace{\\mathbf{W}_2}_{\\text{kernel for channel-2}}\\circledast\\underbrace{\\mathbf{X}_2}_\\text{channel-2}+\\underbrace{\\mathbf{W}_3}_{\\text{kernel for channel-3}}\\circledast\\underbrace{\\mathbf{X}_3}_\\text{channel-3} +\\underbrace{\\mathbf{b}}_\\text{bias of appropriate shape}$$ using separate convolution layers for each channel and adding their output with the bias. Use unit padding and stride = 2.\n",
        "\n",
        "This approach is equivalent to performing the depth-wise convolution channel by channel, and then adding the results.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "htvDyZxp76Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Define channel-wise convolution layers\n",
        "layer_channel0 = tf.keras.layers.Conv2D(\n",
        "        filters = 1,\n",
        "        kernel_size = [3, 3],\n",
        "        strides=(2, 2),\n",
        "        padding = 'same',\n",
        "        kernel_initializer = tf.constant_initializer(np.expand_dims(W[:, :, 0], axis = 0))\n",
        "        )\n",
        "\n",
        "layer_channel1 = tf.keras.layers.Conv2D(\n",
        "        filters = 1,\n",
        "        kernel_size = [3, 3],\n",
        "        strides=(2, 2),\n",
        "        padding = 'same',\n",
        "        kernel_initializer = tf.constant_initializer(np.expand_dims(W[:, :, 1], axis = 0))\n",
        "        )\n",
        "\n",
        "layer_channel2 = tf.keras.layers.Conv2D(\n",
        "        filters = 1,\n",
        "        kernel_size = [3, 3],\n",
        "        strides=(2, 2),\n",
        "        padding = 'same',\n",
        "        kernel_initializer = tf.constant_initializer(np.expand_dims(W[:, :, 2], axis = 0))\n",
        "        )"
      ],
      "metadata": {
        "id": "9vKuotetFuo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Perform channel-wise convolution and add with bias to get the\n",
        "## raw scores map calculated by the neuron.\n",
        "output0 = layer_channel0(np.expand_dims(X[:, :, 0], axis = (0, -1)))\n",
        "output1 = layer_channel1(np.expand_dims(X[:, :, 1], axis = (0, -1)))\n",
        "output2 = layer_channel2(np.expand_dims(X[:, :, 2], axis = (0, -1)))\n",
        "output = output0 + output1 + output2 + b\n",
        "\n",
        "print(f'Convolution applied to channel-0 results in: \\n {tf.squeeze(output0[:, :, :, 0])}')\n",
        "print(f'Convolution applied to channel-1 results in: \\n {tf.squeeze(output1[:, :, :, 0])}')\n",
        "print(f'Convolution applied to channel-2 results in: \\n {tf.squeeze(output2[:, :, :, 0])}')\n",
        "# Adding the convolutions across each channel gives the full convolution output\n",
        "# volume which is the raw score map calculated by the neuron.\n",
        "print(f'The full convolution output volume is the sum of all channel convolutions:\\n {tf.squeeze(output)}')"
      ],
      "metadata": {
        "id": "g5dL4196F8om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Define max-pooling layer.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "yfUDmWyd8ms4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.squeeze(output)"
      ],
      "metadata": {
        "id": "IVJ8-39vzEZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "                                           strides = (1, 1),\n",
        "                                           padding='valid')"
      ],
      "metadata": {
        "id": "-nvihlgQhWDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Apply max-pooling to the output of the convolution layer\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "AojoXJwRhgQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.squeeze(max_pool_2d(output))"
      ],
      "metadata": {
        "id": "MTTjzA89hmD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Load MNIST dataset.\n",
        "\n",
        "Note that in TensorFlow, a typical representation of an image data set is a four-dimensional tensor with axes meanings [number of images, width, height, number of color channels]. In the MNIST dataset, we are reading grayscale images of shape 28 x 28 with only one color channel (a regular RGB color image has 3 color channels). So, we use np.expand_dims() to manually add the last dimension for the image data.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vTQ7MPwXjenu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dXZONdTO8obu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset and adjust shape\n",
        "## Load MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = np.expand_dims(X_train, axis = -1)\n",
        "X_test = np.expand_dims(X_train, axis = -1)\n",
        "\n",
        "num_labels = len(np.unique(y_train))\n",
        "\n",
        "# One-hot encode class labels\n",
        "Y_train = tf.keras.utils.to_categorical(y_train)\n",
        "Y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "# Normalize the samples (images) using the training data\n",
        "xmax = np.amax(X_train)\n",
        "xmin = np.amin(X_train)\n",
        "X_train = (X_train - xmin) / (xmax - xmin) # all train features turn into a number between 0 and 1\n",
        "X_test = (X_test - xmin)/(xmax - xmin)"
      ],
      "metadata": {
        "id": "X9706A_5bsUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create source dataset from input data (this is helpful for pipelining later)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "batch_size = 100 # batch size\n",
        "# Create training batches\n",
        "train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(batch_size)"
      ],
      "metadata": {
        "id": "Wau-eCMfB7CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Define CNN Model\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "K-qnAK3Om4Z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(\n",
        "            filters = 32,\n",
        "            kernel_size = [5, 5],\n",
        "            padding = 'same',\n",
        "            activation = tf.nn.relu\n",
        "        )\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size = [2, 2], strides = 2)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(\n",
        "            filters = 64,\n",
        "            kernel_size = [5, 5],\n",
        "            padding = 'same',\n",
        "            activation = tf.nn.relu\n",
        "        )\n",
        "        self.pool2 = tf.keras.layers.MaxPool2D(pool_size = [2, 2], strides = 2)\n",
        "        self.flatten = tf.keras.layers.Reshape(target_shape=(7 * 7 * 64,))\n",
        "        self.dense1 = tf.keras.layers.Dense(units=1024, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        output = tf.nn.softmax(x)\n",
        "        return output"
      ],
      "metadata": {
        "id": "hoQRtDibncws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Build and train CNN model\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "t69baOU6C0x4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CNN model\n",
        "model = CNN()\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = 1e-03) # optimizer\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()  # loss function\n",
        "\n",
        "# Varible to store training loss per epoch\n",
        "loss_train_epoch = tf.keras.metrics.Mean()\n",
        "\n",
        "# Iterate over epochs\n",
        "nepochs = 10\n",
        "for epoch in range(nepochs):\n",
        "  # Iterate over the batches of the dataset.\n",
        "  for step, train_batch in enumerate(train_dataset):\n",
        "    with tf.GradientTape() as g:\n",
        "      # Compute loss\n",
        "      yhat = model(train_batch[0])\n",
        "      loss = loss_fn(train_batch[1], yhat)\n",
        "\n",
        "    # Calculate gradients\n",
        "    grad = g.gradient(loss, model.trainable_weights)\n",
        "\n",
        "    # Update model\n",
        "    opt.apply_gradients(zip(grad, model.trainable_weights))\n",
        "\n",
        "    # Append training loss\n",
        "    loss_train_epoch(loss)\n",
        "  print('Epoch %d: train loss = %f'%(epoch+1, loss_train_epoch.result()))"
      ],
      "metadata": {
        "id": "P265ObrRCQe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Compile model so it can be evaluated for test set\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HZUw8WELCwMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model so it can be evaluated for test set\n",
        "model.compile(optimizer = opt, loss = loss_fn, metrics = ['acc'])\n",
        "print('\\nAccuracy:', model.evaluate(X_test, Y_test, verbose=0)[1])"
      ],
      "metadata": {
        "id": "59EM722lCsvO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}