{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Load essential libraries**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "CrW3wGfQN2KV"
      },
      "id": "CrW3wGfQN2KV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "valued-lodging",
      "metadata": {
        "id": "valued-lodging"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Mount Google Drive if running on Colab\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "C_OSGWVfxTxy"
      },
      "id": "C_OSGWVfxTxy"
    },
    {
      "cell_type": "code",
      "source": [
        "## Mount Google drive folder if running in Colab\n",
        "if('google.colab' in sys.modules):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount = True)\n",
        "    # Change path below starting from /content/drive/MyDrive/Colab Notebooks/\n",
        "    # depending on how data is organized inside your Colab Notebooks folder in\n",
        "    # Google Drive\n",
        "    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/MSIS Coursework/EvenSem2024MAHE'\n",
        "    DATA_DIR = DIR+'/Data/'\n",
        "else:\n",
        "    DATA_DIR = 'Data/'"
      ],
      "metadata": {
        "id": "VrK5cqGXxXLN"
      },
      "id": "VrK5cqGXxXLN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Load MNIST Data\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "8jG5ivrRX1O-"
      },
      "id": "8jG5ivrRX1O-"
    },
    {
      "cell_type": "code",
      "source": [
        "## Load MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
        "\n",
        "num_labels = len(np.unique(y_train))\n",
        "num_features = X_train.shape[1]\n",
        "num_samples = X_train.shape[0]\n",
        "\n",
        "# One-hot encode class labels\n",
        "Y_train = tf.keras.utils.to_categorical(y_train)\n",
        "Y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "# Normalize the samples (images) using the training data\n",
        "xmax = np.amax(X_train)\n",
        "xmin = np.amin(X_train)\n",
        "X_train = (X_train - xmin) / (xmax - xmin) # all train features turn into a number between 0 and 1\n",
        "X_test = (X_test - xmin)/(xmax - xmin)\n",
        "\n",
        "print('MNIST set')\n",
        "print('---------------------')\n",
        "print('Number of training samples = %d'%(num_samples))\n",
        "print('Number of features = %d'%(num_features))\n",
        "print('Number of output labels = %d'%(num_labels))"
      ],
      "metadata": {
        "id": "qs1J2W_qX0xw"
      },
      "id": "qs1J2W_qX0xw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Hyperparameters for the model\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "bir5GciL4X6U"
      },
      "id": "bir5GciL4X6U"
    },
    {
      "cell_type": "code",
      "source": [
        "## Hyperparameters for the model\n",
        "batch_size = 256\n",
        "max_epochs = 50\n",
        "learning_rate = 1e-03\n",
        "reg_strength = 0.1"
      ],
      "metadata": {
        "id": "umisXgSj4a08"
      },
      "id": "umisXgSj4a08",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "We have looked at 2 different approaches to build custom models using TensorFlow 2:\n",
        "\n",
        "1. sequential API\n",
        "2. model subclassing ([Making new layers and models via subclassing](https://www.tensorflow.org/guide/keras/making_new_layers_and_models_via_subclassing))\n",
        "\n",
        "The 3rd, and the last approach is via the functional API.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "kjk0YnbgGsr8"
      },
      "id": "kjk0YnbgGsr8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Approach-1**: here we build the model using the sequential API of TensorFlow Keras, compile, and train it.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "F3SJL2TyyCX3"
      },
      "id": "F3SJL2TyyCX3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model architecture (2 layers, 128 nodes in hidden layer)\n",
        "model = Sequential()\n",
        "model.add(Dense(128,\n",
        "                dtype = 'float64',\n",
        "                activation = tf.nn.leaky_relu,\n",
        "                kernel_regularizer = tf.keras.regularizers.l2(l2 = reg_strength)\n",
        "                ))\n",
        "model.add(Dense(num_labels,\n",
        "                dtype = 'float64',\n",
        "                activation = tf.keras.activations.softmax,\n",
        "                kernel_regularizer = tf.keras.regularizers.l2(l2 = reg_strength)\n",
        "                ))\n",
        "\n",
        "# Compile model\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = learning_rate) # optimizer\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()  # loss function\n",
        "model.compile(optimizer = opt, loss = loss_fn, metrics = ['acc'])\n",
        "\n",
        "# Train model and simultaneously test on the test set\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = max_epochs,\n",
        "                    validation_data = (X_test, Y_test))"
      ],
      "metadata": {
        "id": "GzCLlmGd2SSL"
      },
      "id": "GzCLlmGd2SSL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Plot train and test loss vs. epoch and train and test accuracies vs. epoch\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "eugkmOeF5j0U"
      },
      "id": "eugkmOeF5j0U"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot train and test loss vs. epoch and\n",
        "# train and test accuracies vs. epoch:\n",
        "fig, ax = plt.subplots(1, 2, figsize = (8, 4))\n",
        "fig.tight_layout(pad = 4.0)\n",
        "ax[0].plot( history.history['loss'], 'b', label = 'Train')\n",
        "ax[0].plot( history.history['val_loss'], 'r', label = 'Test')\n",
        "ax[0].set_xlabel('Epoch', fontsize = 12)\n",
        "ax[0].set_ylabel('Loss value', fontsize = 12)\n",
        "ax[0].legend()\n",
        "ax[0].set_title(f'Loss vs. Epoch for reg. strength {reg_strength}', fontsize = 14);\n",
        "\n",
        "ax[1].plot( history.history['acc'], 'b', label = 'Train')\n",
        "ax[1].plot( history.history['val_acc'], 'r', label = 'Test')\n",
        "ax[1].set_xlabel('Epoch', fontsize = 12)\n",
        "ax[1].set_ylabel('Accuracy', fontsize = 12)\n",
        "ax[1].legend()\n",
        "ax[1].set_title('Accuracy vs. Epoch for reg. strength 0.1', fontsize = 14);"
      ],
      "metadata": {
        "id": "VmW13XNY5nxV"
      },
      "id": "VmW13XNY5nxV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Approach-2**: here we build the model by subclassing the TensorFlow Keras $\\texttt{Model}$ class followed by definition of of layers in $\\texttt{__init__}$ and implementation of the model's forward pass in $\\texttt{call()}$.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "X1MGY9oF8CHg"
      },
      "id": "X1MGY9oF8CHg"
    },
    {
      "cell_type": "code",
      "source": [
        "## Define 2-layer neural network architecture with 128 nodes in the hidden layer\n",
        "# Define model\n",
        "class Model(tf.keras.models.Model):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        initializer = tf.keras.initializers.RandomUniform(minval=-0.5, maxval=0.5)\n",
        "        self.layer1 = tf.keras.layers.Dense(128,\n",
        "                                            dtype = 'float64',\n",
        "                                            bias_initializer = initializer,\n",
        "                                            activation = tf.nn.leaky_relu,\n",
        "                                            kernel_regularizer = tf.keras.regularizers.l2(l2 = reg_strength)\n",
        "                                            )\n",
        "        self.layer2 = tf.keras.layers.Dense(num_labels,\n",
        "                                            dtype = 'float64',\n",
        "                                            bias_initializer = initializer,\n",
        "                                            activation = tf.keras.activations.softmax,\n",
        "                                            kernel_regularizer = tf.keras.regularizers.l2(l2 = reg_strength)\n",
        "                                            )\n",
        "\n",
        "    # Forward pass for the model\n",
        "    def call(self, inputs):\n",
        "        a = self.layer1(inputs)\n",
        "        a = self.layer2(a)\n",
        "        return a"
      ],
      "metadata": {
        "id": "qgeD1NmfRqkT"
      },
      "id": "qgeD1NmfRqkT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Compile and train the model.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "EZyM0MekDtFI"
      },
      "id": "EZyM0MekDtFI"
    },
    {
      "cell_type": "code",
      "source": [
        "## Compile model\n",
        "model = Model()\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = learning_rate) # optimizer\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()  # loss function\n",
        "model.compile(optimizer = opt, loss = loss_fn, metrics = ['acc'])\n",
        "\n",
        "# Train model and simultaneously test on the test set\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size = 100,\n",
        "                    epochs = max_epochs,\n",
        "                    validation_data = (X_test, Y_test))"
      ],
      "metadata": {
        "id": "d3OcZ7XZT5HZ"
      },
      "id": "d3OcZ7XZT5HZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "In **Approach-2** where we subclassed the Model class, we can also explicitly write down the optimization step using $\\texttt{GradientTape()}$ and train the model\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "k0H0scBfV3wH"
      },
      "id": "k0H0scBfV3wH"
    },
    {
      "cell_type": "code",
      "source": [
        "## Convert numpy to tf.data.datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(batch_size)"
      ],
      "metadata": {
        "id": "SW3BgQ3EW56s"
      },
      "id": "SW3BgQ3EW56s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Function to compute gradient of loss and update weights\n",
        "@tf.function\n",
        "def train(model, loss_fn, opt, input):\n",
        "  with tf.GradientTape() as g:\n",
        "    pred = model(input[0])\n",
        "    loss_batch = loss_fn(input[1], pred)\n",
        "  gradients = g.gradient(loss_batch, model.trainable_variables)\n",
        "  opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss_batch"
      ],
      "metadata": {
        "id": "_-PERnpFDMwT"
      },
      "id": "_-PERnpFDMwT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create neural network model with 128 nodes in the hidden layer\n",
        "model = Model()\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = learning_rate) # optimizer\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()  # loss function\n",
        "\n",
        "# Varible to store training loss per epoch\n",
        "loss_train_epoch = tf.keras.metrics.Mean()\n",
        "loss_train_epoch_plot = np.empty(max_epochs)\n",
        "\n",
        "# Iterate over epochs\n",
        "for epoch in range(max_epochs):\n",
        "  for step, train_batch_features in enumerate(train_dataset):\n",
        "    loss_batch = train(model, loss_fn, opt, train_batch_features)\n",
        "    # Append training loss\n",
        "    loss_train_epoch(loss_batch)\n",
        "  loss_train_epoch_plot[epoch] = loss_train_epoch.result().numpy()\n",
        "  print(f'Epoch {epoch+1}, loss = {loss_train_epoch_plot[epoch]}')"
      ],
      "metadata": {
        "id": "Ra341NtdTjTD"
      },
      "id": "Ra341NtdTjTD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Approach-3**: here we build the model using the functional API of TensorFlow.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Ljcm4VTm1j9f"
      },
      "id": "Ljcm4VTm1j9f"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MMVOs9Jk1noX"
      },
      "id": "MMVOs9Jk1noX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Siamese neural network\n",
        "\n",
        "![](https://dsm01pap002files.storage.live.com/y4m4YOFCC_sbCAbXCq7NQU6A2WruYAWuAighVI6h0pyQ8cPKVLxXOsmoDld5x30YlDiYqN_8O92TvfkGAoj3mGOWI8a3zazkfvVjccQZdimepRQ6a3QTe7CjNtUgXDp5xGZgseO_ODki5iA1lgikBzCy0vg52LJwyvzfLsT7ZjxapEy9Ej2aYbN27m0fdesXHHA?width=415&height=372&cropmode=none)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6vcy6qd1Jii8"
      },
      "id": "6vcy6qd1Jii8"
    },
    {
      "cell_type": "code",
      "source": [
        "## Load MNIST dataset without flattening (reshaping) the images\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "JU71MVBPJop5"
      },
      "id": "JU71MVBPJop5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Normalize the samples (images) using the training data\n",
        "xmax = np.amax(X_train)\n",
        "xmin = np.amin(X_train)\n",
        "X_train = (X_train - xmin) / (xmax - xmin) # all train features turn into a number between 0 and 1\n",
        "X_test = (X_test - xmin)/(xmax - xmin)"
      ],
      "metadata": {
        "id": "JBLaLXowLC0V"
      },
      "id": "JBLaLXowLC0V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Function to create pairs of images** (for function source, [click here](https://keras.io/examples/vision/siamese_contrastive/))\n",
        "\n",
        "We will train the model to differentiate between digits of different classes. For example, digit 0 needs to be differentiated from the rest of the digits (1 through 9), digit 1 - from 0 and 2 through 9, and so on. To carry this out, we will select N random images from class A (for example, for digit 0) and pair them with N random images from another class B (for example, for digit 1). Then, we can repeat this process for all classes of digits (until digit 9). Once we have paired digit 0 with other digits, we can repeat this process for the remaining classes for the rest of the digits (from 1 until 9).\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ilG96fw1JxlF"
      },
      "id": "ilG96fw1JxlF"
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pairs(x, y):\n",
        "    \"\"\"Creates a tuple containing image pairs with corresponding label.\n",
        "\n",
        "    Arguments:\n",
        "        x: List containing images, each index in this list corresponds to one image.\n",
        "        y: List containing labels, each label with datatype of `int`.\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing two numpy arrays as (pairs_of_samples, labels),\n",
        "        where pairs_of_samples' shape is (2len(x), 2,n_features_dims) and\n",
        "        labels are a binary array of shape (2len(x)).\n",
        "    \"\"\"\n",
        "\n",
        "    num_classes = max(y) + 1\n",
        "    digit_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
        "\n",
        "    pairs = []\n",
        "    labels = []\n",
        "\n",
        "    for idx1 in range(len(x)):\n",
        "        # add a matching example\n",
        "        x1 = x[idx1]\n",
        "        label1 = y[idx1]\n",
        "        idx2 = random.choice(digit_indices[label1])\n",
        "        x2 = x[idx2]\n",
        "\n",
        "        pairs += [[x1, x2]]\n",
        "        labels += [1]\n",
        "\n",
        "        # add a non-matching example\n",
        "        label2 = random.randint(0, num_classes - 1)\n",
        "        while label2 == label1:\n",
        "            label2 = random.randint(0, num_classes - 1)\n",
        "\n",
        "        idx2 = random.choice(digit_indices[label2])\n",
        "        x2 = x[idx2]\n",
        "\n",
        "        pairs += [[x1, x2]]\n",
        "        labels += [0]\n",
        "\n",
        "    return np.array(pairs), np.array(labels).astype(\"float32\")"
      ],
      "metadata": {
        "id": "w83LL_YnJyvB"
      },
      "id": "w83LL_YnJyvB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Create train and test image pairs\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "K0v2DXetLKvv"
      },
      "id": "K0v2DXetLKvv"
    },
    {
      "cell_type": "code",
      "source": [
        "# Make train pairs\n",
        "X_train_pairs, y_train_pairs = make_pairs(X_train, y_train)\n",
        "\n",
        "# Make test pairs\n",
        "X_test_pairs, y_test_pairs = make_pairs(X_test, y_test)"
      ],
      "metadata": {
        "id": "Pk0kJAy_K8sP"
      },
      "id": "Pk0kJAy_K8sP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Function for visualizing the paired data (for function source, [click here](https://keras.io/examples/vision/siamese_contrastive/))\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wY2xxZPTKgsY"
      },
      "id": "wY2xxZPTKgsY"
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(pairs, labels, to_show=6, num_col=3, predictions=None, test=False):\n",
        "    \"\"\"Creates a plot of pairs and labels, and prediction if it's test dataset.\n",
        "\n",
        "    Arguments:\n",
        "        pairs: Numpy Array, of pairs to visualize, having shape\n",
        "               (Number of pairs, 2, 28, 28).\n",
        "        to_show: Int, number of examples to visualize (default is 6)\n",
        "                `to_show` must be an integral multiple of `num_col`.\n",
        "                 Otherwise it will be trimmed if it is greater than num_col,\n",
        "                 and incremented if if it is less then num_col.\n",
        "        num_col: Int, number of images in one row - (default is 3)\n",
        "                 For test and train respectively, it should not exceed 3 and 7.\n",
        "        predictions: Numpy Array of predictions with shape (to_show, 1) -\n",
        "                     (default is None)\n",
        "                     Must be passed when test=True.\n",
        "        test: Boolean telling whether the dataset being visualized is\n",
        "              train dataset or test dataset - (default False).\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define num_row\n",
        "    # If to_show % num_col != 0\n",
        "    #    trim to_show,\n",
        "    #       to trim to_show limit num_row to the point where\n",
        "    #       to_show % num_col == 0\n",
        "    #\n",
        "    # If to_show//num_col == 0\n",
        "    #    then it means num_col is greater then to_show\n",
        "    #    increment to_show\n",
        "    #       to increment to_show set num_row to 1\n",
        "    num_row = to_show // num_col if to_show // num_col != 0 else 1\n",
        "\n",
        "    # `to_show` must be an integral multiple of `num_col`\n",
        "    #  we found num_row and we have num_col\n",
        "    #  to increment or decrement to_show\n",
        "    #  to make it integral multiple of `num_col`\n",
        "    #  simply set it equal to num_row * num_col\n",
        "    to_show = num_row * num_col\n",
        "\n",
        "    # Plot the images\n",
        "    fig, axes = plt.subplots(num_row, num_col, figsize=(5, 5))\n",
        "    for i in range(to_show):\n",
        "\n",
        "        # If the number of rows is 1, the axes array is one-dimensional\n",
        "        if num_row == 1:\n",
        "            ax = axes[i % num_col]\n",
        "        else:\n",
        "            ax = axes[i // num_col, i % num_col]\n",
        "\n",
        "        ax.imshow(tf.concat([pairs[i][0], pairs[i][1]], axis=1), cmap=\"gray\")\n",
        "        ax.set_axis_off()\n",
        "        if test:\n",
        "            ax.set_title(\"True: {} | Pred: {:.5f}\".format(labels[i], predictions[i][0]))\n",
        "        else:\n",
        "            ax.set_title(\"Label: {}\".format(labels[i]))\n",
        "    if test:\n",
        "        plt.tight_layout(rect=(0, 0, 1.9, 1.9), w_pad=0.0)\n",
        "    else:\n",
        "        plt.tight_layout(rect=(0, 0, 1.5, 1.5))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "WYnkRG4NKkNp"
      },
      "id": "WYnkRG4NKkNp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Visualize some training samples. Note that the label is 1 if both pairs if images are the same digits and 0 otherwise.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "k0oMMQOzKn_p"
      },
      "id": "k0oMMQOzKn_p"
    },
    {
      "cell_type": "code",
      "source": [
        "visualize(X_train_pairs[:-1], y_train_pairs[:-1], to_show = 4, num_col = 4)"
      ],
      "metadata": {
        "id": "WuCFjLDCKoml"
      },
      "id": "WuCFjLDCKoml",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}