{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dEgRpy3952M"
      },
      "outputs": [],
      "source": [
        "## Load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9W_1_v_6yq7"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T7eUtw7Mh0z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1e2N5S8MlCU"
      },
      "outputs": [],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Mount Google Drive if running in Colab\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "FbaFOIn_CDuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Mount Google drive folder if running in Colab\n",
        "if('google.colab' in sys.modules):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount = True)\n",
        "    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/MSIS Coursework/EvenSem2024MAHE'\n",
        "    DATA_DIR = DIR + '/Data/'\n",
        "    os.chdir(DIR)\n",
        "else:\n",
        "    DATA_DIR = 'Data/'"
      ],
      "metadata": {
        "id": "02xk1yt7CE1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16BpVeIWIOks"
      },
      "source": [
        "---\n",
        "\n",
        "Load diabetes data\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5kaKFKSIQgu"
      },
      "outputs": [],
      "source": [
        "## Load diabetes data\n",
        "file = DATA_DIR+'diabetes_regression1.csv'\n",
        "df= pd.read_csv(file, header = 0)\n",
        "\n",
        "print('Diabetes dataset')\n",
        "print('-----------')\n",
        "print('Initial number of samples = %d'%(df.shape[0]))\n",
        "print('Initial number of features = %d\\n'%(df.shape[1]))\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create lists of ordinal, categorical, and continuous features\n",
        "#categorical_features =  ['GENDER', 'BMILEVEL']\n",
        "categorical_features =  ['GENDER']\n",
        "continuous_features = df.drop(categorical_features, axis = 1).columns.tolist()\n",
        "print(categorical_features)\n",
        "print(continuous_features)"
      ],
      "metadata": {
        "id": "AJE5ehBOClXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Assign 'category' datatype to categorical columns\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "J3NyP_EoDG1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Assign 'category' datatype to ordinal and categorical columns\n",
        "print(df.dtypes)\n",
        "df[categorical_features] = df[categorical_features].astype('category')\n",
        "print('----')\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "-dVFfOBlDJ5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Remove the target variable column from the list of continuous features\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "m95YNt2eDUJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Remove the target variable column from the list of continuous features\n",
        "continuous_features.remove('Y')"
      ],
      "metadata": {
        "id": "XuQGzpefDUqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train and test split of the data\n",
        "X = df.drop('Y', axis = 1)\n",
        "y = df['Y']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
        "\n",
        "num_features = X_train.shape[0]\n",
        "num_samples = X_train.shape[1]\n",
        "\n",
        "print('Diabetes data set')\n",
        "print('---------------------')\n",
        "print('Number of training samples = %d'%(num_samples))\n",
        "print('Number of features = %d'%(num_features))"
      ],
      "metadata": {
        "id": "tn-qjRocE8Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Build pipeline for categorical and continuous features\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "SKqSu9e7G-fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Build pipeline for categorical and continuous features\n",
        "\n",
        "# Pipeline object for categorical (features\n",
        "categorical_transformer = Pipeline(steps = [('onehotenc', OneHotEncoder(handle_unknown = 'ignore'))])\n",
        "\n",
        "# Pipeline object for continuous features\n",
        "continuous_transformer = Pipeline(steps = [('scaler', RobustScaler())])\n",
        "\n",
        "# Create a preprocessor object for all features\n",
        "preprocessor = ColumnTransformer(transformers = [('continuous', continuous_transformer, continuous_features),\n",
        "                                                 ('categorical', categorical_transformer, categorical_features)\n",
        "                                                ],\n",
        "                                 remainder = 'passthrough'\n",
        "                                 )"
      ],
      "metadata": {
        "id": "FKAqkz1GHGvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Apply preprocessor (fit and transform) to train data followed by transform to test data\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "QWWGe-uRPfur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Fit and transform train data using preprocessor\n",
        "X_train_transformed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "# Transform test data using preprocessor\n",
        "X_test_transformed = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "RvrUIw4SHzO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Define neural network architecture for regression\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "gfbydCWNOfWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define neural network architecture\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation='relu', input_shape=(X_train_transformed.shape[1], ), kernel_regularizer = keras.regularizers.l2(l=0.1)),\n",
        "    layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "JKVA8gqyOhsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the neural network model\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = 1e-04)\n",
        "model.compile(optimizer = opt, loss = 'mean_squared_error')"
      ],
      "metadata": {
        "id": "mWDSNSXMIyly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_transformed, Y_train, epochs = 10000, batch_size = 32, validation_data=(X_test_transformed, Y_test))"
      ],
      "metadata": {
        "id": "b7prUjNlI0zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Plot train and test loss as a function of epoch\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "fhWlxfi9GQWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot train and test loss as a function of epoch:\n",
        "fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
        "fig.tight_layout(pad = 4.0)\n",
        "ax.plot( history.history['loss'], 'b', label = 'Train')\n",
        "ax.plot( history.history['val_loss'], 'r', label = 'Test')\n",
        "ax.set_xlabel('Epoch', fontsize = 12)\n",
        "ax.set_ylabel('Loss value', fontsize = 12)\n",
        "ax.legend()\n",
        "ax.set_title('Loss vs. Epoch for reg. strength 1.0', fontsize = 14);"
      ],
      "metadata": {
        "id": "LYSUu_SwGQ-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Compare the true and predicted values\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "GRS_vh61Qz8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Compare the true and predicted values\n",
        "np.column_stack((Y_test, model.predict(X_test_transformed)))"
      ],
      "metadata": {
        "id": "ASvIE-SWM9To"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}