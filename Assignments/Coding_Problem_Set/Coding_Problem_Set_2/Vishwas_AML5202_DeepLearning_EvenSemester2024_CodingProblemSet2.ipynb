{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5dEgRpy3952M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\vp140\\.conda\\envs\\pycaretenv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from keras.datasets import mnist\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G9W_1_v_6yq7"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4T7eUtw7Mh0z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q1e2N5S8MlCU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.15.0'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16BpVeIWIOks"
      },
      "source": [
        "---\n",
        "\n",
        "Load MNIST Data\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E5kaKFKSIQgu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST set\n",
            "---------------------\n",
            "Number of training samples = 60000\n",
            "Number of features = 784\n",
            "Number of output labels = 10\n"
          ]
        }
      ],
      "source": [
        "## Load MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.transpose(1, 2, 0)\n",
        "X_test = X_test.transpose(1, 2, 0)\n",
        "X_train = X_train.reshape(X_train.shape[0]*X_train.shape[1], X_train.shape[2])\n",
        "X_test = X_test.reshape(X_test.shape[0]*X_test.shape[1], X_test.shape[2])\n",
        "\n",
        "num_labels = len(np.unique(y_train))\n",
        "num_features = X_train.shape[0]\n",
        "num_samples = X_train.shape[1]\n",
        "\n",
        "# One-hot encode class labels\n",
        "Y_train = tf.keras.utils.to_categorical(y_train).T\n",
        "Y_test = tf.keras.utils.to_categorical(y_test).T\n",
        "\n",
        "\n",
        "# Normalize the samples (images)\n",
        "xmax = np.amax(X_train)\n",
        "xmin = np.amin(X_train)\n",
        "X_train = (X_train - xmin) / (xmax - xmin) # all train features turn into a number between 0 and 1\n",
        "X_test = (X_test - xmin)/(xmax - xmin)\n",
        "\n",
        "print('MNIST set')\n",
        "print('---------------------')\n",
        "print('Number of training samples = %d'%(num_samples))\n",
        "print('Number of features = %d'%(num_features))\n",
        "print('Number of output labels = %d'%(num_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrXipxwrJ0_8"
      },
      "source": [
        "---\n",
        "\n",
        "A generic layer class with forward and backward methods\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N4pKUhCyMrWm"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "  def __init__(self):\n",
        "    self.input = None\n",
        "    self.output = None\n",
        "\n",
        "  def forward(self, input):\n",
        "    pass\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdLfiQSlOSUU"
      },
      "source": [
        "---\n",
        "\n",
        "The softmax classifier steps for a batch of comprising $b$ samples represented as the $785\\times b$-matrix (784 pixel values plus the bias feature absorbed as its last row) $$\\mathbf{X} = \\begin{bmatrix}\\mathbf{x}^{(0)},\\mathbf{x}^{(1)},\\ldots,\\mathbf{x}^{(b-1)}\\end{bmatrix}$$ with one-hot encoded true labels represented as the $10\\times b$-matrix (10 possible categories) $$\\mathbf{Y}=\\begin{bmatrix}\\mathbf{y}^{(0)}&\\ldots&\\mathbf{y}^{(b-1)}\\end{bmatrix}$$ using a randomly initialized $10\\times785$-weights matrix $\\mathbf{W}$:\n",
        "\n",
        "1. Calculate $10\\times b$-raw scores matrix : $$\\begin{align*}\\begin{bmatrix}\\mathbf{z}^{(0)}&\\ldots&\\mathbf{z}^{(b-1)}\\ldots\\end{bmatrix} &= \\mathbf{W}\\begin{bmatrix}\\mathbf{x}^{(0)}&\\ldots&\\mathbf{x}^{(b-1)}\\ldots\\end{bmatrix}\\\\&=\\begin{bmatrix}\\mathbf{W}\\mathbf{x}^{(0)}&\\ldots&\\mathbf{W}\\mathbf{x}^{(b-1)}\\end{bmatrix}\\\\\\Rightarrow \\mathbf{Z} &= \\mathbf{WX}.\\end{align*}$$\n",
        "2. Calculate $10\\times b$-softmax predicted probabilities matrix: $$\\begin{align*}\\begin{bmatrix}\\mathbf{a}^{(0)}&\\ldots&\\mathbf{a}^{(b-1)}\\end{bmatrix} &= \\begin{bmatrix}\\text{softmax}\\left(\\mathbf{z}^{(0)}\\right)&\\ldots&\\text{softmax}\\left(\\mathbf{z}^{(b-1)}\\right)\\end{bmatrix}\\\\\\Rightarrow\\mathbf{A} &= \\text{softmax}(\\mathbf{Z}).\\end{align*}$$\n",
        "3. Predicted probability matrix get a new name: $\\hat{\\mathbf{Y}} = \\mathbf{A}.$\n",
        "4. The crossentropy (CCE) loss for the $i$th sample is $$L_i = \\sum_{k=0}^9-y^{(i)}\\log\\left(\\hat{y}^{(i)}_k\\right) = -{\\mathbf{y}^{(i)}}^\\mathrm{T}\\log\\left(\\mathbf{y}^{(i)}\\right)$$ which leads to the average crossentropy (CCE) batch loss for the batch as:\n",
        "$$\\begin{align*}L &=\\frac{1}{b}\\left[L_0+\\cdots+L_{b-1}\\right]\\\\&\\frac{1}{b}\\left[\\sum_{k=0}^9-y^{(0)}\\log\\left(\\hat{y}^{(0)}_k\\right)+\\cdots+\\sum_{k=0}^9-y^{(b-1)}\\log\\left(\\hat{y}^{(b-1)}_k\\right)\\right]\\\\&=\\frac{1}{b}\\left[-{\\mathbf{y}^{(0)}}^{\\mathrm{T}}\\log\\left(\\hat{\\mathbf{y}}^{(0)}\\right)+\\cdots+-{\\mathbf{y}^{(b-1)}}^{\\mathrm{T}}\\log\\left(\\hat{\\mathbf{y}}^{(b-1)}\\right)\\right].\\end{align*}$$\n",
        "5. The computational graph for the samples in the batch are presented below:\n",
        "\n",
        "$\\hspace{1.5in}\\begin{align*}L_0\\\\{\\color{yellow}\\downarrow}\\\\ \\hat{\\mathbf{y}}^{(0)} &= \\mathbf{a}^{(0)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{z}^{(0)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{W}\\end{align*}$$\\qquad\\cdots\\qquad$$\\begin{align*} L_{b-1}\\\\{\\color{yellow}\\downarrow}\\\\ \\hat{\\mathbf{y}}^{(b-1)} &= \\mathbf{a}^{(b-1)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{z}^{(b-1)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{W}\\end{align*}$\n",
        "6. Calculate the gradient of the average batch loss w.r.t. weights as: $$\\begin{align*}\\Rightarrow \\nabla_\\mathbf{W}(L) &= \\frac{1}{b}\\left[\\nabla_\\mathbf{W}\\left(L_0\\right)+\\cdots+\\nabla_\\mathbf{W}\\left(L_{b-1}\\right)\\right]\\\\&= \\frac{1}{b}\\left(\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(0)}\\right) \\times\\nabla_{\\mathbf{z}^{(0)}}\\left(\\hat{\\mathbf{y}}^{(0)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(0)}}(L_0)\\right]}_{\\text{sample}\\,0}+\\cdots+\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(b-1)}\\right) \\times\\nabla_{\\mathbf{z}^{(b-1)}}\\left(\\hat{\\mathbf{y}}^{(b-1)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(b-1)}}(L_{b-1})\\right]}_{\\text{sample}\\,b-1}\\right)\\\\&=\\frac{1}{b}\\left(\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(0)}\\right) \\times\\nabla_{\\mathbf{z}^{(0)}}\\left({\\mathbf{a}}^{(0)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(0)}}(L_0)\\right]}_{\\text{sample}\\,0}+\\cdots+\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(b-1)}\\right) \\times\\nabla_{\\mathbf{z}^{(b-1)}}\\left({\\mathbf{a}}^{(b-1)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(b-1)}}(L_{b-1})\\right]}_{\\text{sample}\\,b-1}\\right).\\end{align*}$$\n",
        "10. The full gradient can be written as\n",
        "\n",
        "![](https://onedrive.live.com/embed?resid=37720F927B6DDC34%21103292&authkey=%21AMoosVj6GqUSvpc&width=660)\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9YGwzbz72CZ"
      },
      "source": [
        "---\n",
        "\n",
        "CCE loss and its gradient for the batch samples:\n",
        "\n",
        "$$\\begin{align*}L &=\\frac{1}{b}\\left[L_0+\\cdots+L_{b-1}\\right]\\\\&=\\frac{1}{b}\\left[\\sum_{k=0}^9-y^{(0)}\\log\\left(\\hat{y}^{(0)}_k\\right)+\\cdots+\\sum_{k=0}^9-y^{(b-1)}\\log\\left(\\hat{y}^{(b-1)}_k\\right)\\right]\\\\&=\\frac{1}{b}\\left[-{\\mathbf{y}^{(0)}}^{\\mathrm{T}}\\log\\left(\\hat{\\mathbf{y}}^{(0)}\\right)+\\cdots+-{\\mathbf{y}^{(b-1)}}^{\\mathrm{T}}\\log\\left(\\hat{\\mathbf{y}}^{(b-1)}\\right)\\right].\\end{align*}$$\n",
        "\n",
        "$$\\begin{align*}\\begin{bmatrix}\\nabla_{\\hat{\\mathbf{y}}^{(0)}}(L_0)&\\ldots&\\nabla_{\\hat{\\mathbf{y}}^{(b-1)}}(L_{b-1})\\end{bmatrix}=\\begin{bmatrix}-y_0^{(0)}/\\hat{y}_0^{(0)}&\\cdots&-y_0^{(0)}/\\hat{y}_0^{(b-1)}\\\\-y_1^{(0)}/\\hat{y}_1^{(0)}&\\ldots&-y_1^{(b-1)}/\\hat{y}_1^{(b-1)}\\\\-y_2^{(0)}/\\hat{y}_2^{(0)}&\\cdots&-y_2^{(b-1)}/\\hat{y}_2^{(b-1)}\\\\\\vdots\\\\-y_9^{(0)}/\\hat{y}_9^{(0)}&\\cdots&-y_9^{(b-1)}/\\hat{y}_9^{(b-1)}\\end{bmatrix}\\end{align*}$$\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QZttzTIn8WcH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]]\n",
            "[[0.8  0.1  0.1 ]\n",
            " [0.05 0.5  0.4 ]\n",
            " [0.15 0.4  0.5 ]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[-1.25,  0.  ,  0.  ],\n",
              "       [ 0.  ,  0.  , -2.5 ],\n",
              "       [ 0.  , -2.5 ,  0.  ]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y = np.array([[1, 0, 0],[0, 0, 1], [0, 1, 0]])\n",
        "print(Y)\n",
        "Yhat = np.array([[0.8, 0.1, 0.1],[0.05, .5, .4], [.15, .4, 0.5]])\n",
        "print(Yhat)\n",
        "np.mean(np.sum(-Y*np.log(Yhat), axis = 0))\n",
        "-Y/Yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hdXSGW2s7zKd"
      },
      "outputs": [],
      "source": [
        "## Define the loss function and its gradient\n",
        "def cce(Y, Yhat):\n",
        "  return(np.mean(np.sum(-Y*np.log(Yhat), axis = 0)))\n",
        "\n",
        "def cce_gradient(Y, Yhat):\n",
        "  return(-Y/Yhat)\n",
        "\n",
        "# TensorFlow in-built function for categorical crossentropy loss\n",
        "#cce = tf.keras.losses.CategoricalCrossentropy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smgXLg9p65HV"
      },
      "source": [
        "---\n",
        "\n",
        "Softmax activation layer class:\n",
        "\n",
        "**Forward**:\n",
        "$$\\begin{align*}\\begin{bmatrix}\\mathbf{a}^{(0)}&\\ldots&\\mathbf{a}^{(b-1)}\\end{bmatrix} &= \\begin{bmatrix}\\text{softmax}\\left(\\mathbf{z}^{(0)}\\right)&\\ldots&\\text{softmax}\\left(\\mathbf{z}^{(b-1)}\\right)\\end{bmatrix}\\\\\\Rightarrow\\mathbf{A} &= \\text{softmax}(\\mathbf{Z}).\\end{align*}$$\n",
        "\n",
        "**Backward**:\n",
        "$$\\begin{align*}\\begin{bmatrix}\\nabla_{\\mathbf{z}^{(0)}}(L_0)&\\ldots&\\nabla_{\\mathbf{z}^{(b-1)}}(L_{b-1})\\end{bmatrix} &= \\begin{bmatrix}\\nabla_{\\mathbf{z}^{(0)}}\\left({\\mathbf{a}}^{(0)}\\right)\\times\\nabla_{\\mathbf{a}^{(0)}}(L_0)&\\cdots&\\nabla_{\\mathbf{z}^{(b-1)}}\\left({\\mathbf{a}}^{(b-1)}\\right)\\times\\nabla_{\\mathbf{a}^{(b-1)}}(L_{b-1})\\end{bmatrix}\\end{align*}$$\n",
        "\n",
        "![](https://onedrive.live.com/embed?resid=37720F927B6DDC34%21103299&authkey=%21AIPPR63BJ3UybA8&width=928&height=99)\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4x1Xn3AbJlNy"
      },
      "outputs": [],
      "source": [
        "## Softmax activation layer class\n",
        "class Softmax(Layer):\n",
        "  def forward(self, input):\n",
        "    self.input = input\n",
        "    self.output = tf.nn.softmax(self.input, axis = 0).numpy()\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate = None):\n",
        "    ## Following is the inefficient way of calculating the backward gradient\n",
        "    softmax_gradient = np.empty((self.input.shape[0], output_gradient.shape[1]), dtype = np.float64)\n",
        "    for b in range(softmax_gradient.shape[1]):\n",
        "      softmax_gradient[:, b] = np.dot((np.identity(self.output.shape[0])-self.output[:, b].reshape(-1, 1).T) * self.output[:, b].reshape(-1, 1), output_gradient[:, b])\n",
        "    return(softmax_gradient)\n",
        "    ## Following is the efficient of calculating the backward gradient\n",
        "    #T = (np.transpose(np.identity(self.output.shape[0]) - np.atleast_2d(self.output).T[:, np.newaxis, :], (1, 2, 0)) * np.atleast_2d(self.output))\n",
        "    #return(np.einsum('ijk, ik -> jk', T, output_gradient))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkPFfd1U68dj"
      },
      "source": [
        "---\n",
        "\n",
        "Dense layer class:\n",
        "\n",
        "**Forward**:\n",
        "$$$$\\begin{align*}\\begin{bmatrix}\\mathbf{z}^{(0)}&\\ldots&\\mathbf{z}^{(b-1)}\\ldots\\end{bmatrix} &= \\mathbf{W}\\begin{bmatrix}\\mathbf{z}^{(0)}&\\ldots&\\mathbf{z}^{(b-1)}\\ldots\\end{bmatrix}\\\\&=\\begin{bmatrix}\\mathbf{W}\\mathbf{z}^{(0)}&\\ldots&\\mathbf{W}\\mathbf{z}^{(b-1)}\\end{bmatrix}\\\\\\Rightarrow \\mathbf{Z} &= \\mathbf{WX}.\\end{align*}$$$$\n",
        "\n",
        "**Backward**:\n",
        "$$\\begin{align*}\\nabla_\\mathbf{W}(L)&=\\frac{1}{b}\\left[\\nabla_{\\mathbf{W}}(\\mathbf{z}^{(0)})\\times\\nabla_{\\mathbf{z^{(0)}}}(L) +\\cdots+ \\nabla_{\\mathbf{W}}(\\mathbf{z}^{(b-1)})\\times\\nabla_{\\mathbf{z^{(b-1)}}}(L)\\right]\\\\&=\\frac{1}{b}\\left[\\nabla_{\\mathbf{z^{(0)}}}(L_0){\\mathbf{x}^{(0)}}^\\mathrm{T}+\\cdots+\\nabla_{\\mathbf{z^{(b-1)}}}(L_{b-1}) {\\mathbf{x}^{(b-1)}}^\\mathrm{T}\\right].\\end{align*}$$\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8ctXhZYCTmHK"
      },
      "outputs": [],
      "source": [
        "## Dense layer class\n",
        "class Dense(Layer):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.weights = np.empty((output_size, input_size+1))  # bias trick\n",
        "        self.weights[:, :-1] = 0.01*np.random.randn(output_size, input_size)\n",
        "        self.weights[:, -1] = 0.01 # set all bias values to the same nonzero constant\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = np.vstack([input, np.ones((1, input.shape[1]))]) # bias trick\n",
        "        self.output = np.dot(self.weights, self.input)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        ## Following is the inefficient way of calculating the backward gradient\n",
        "        dense_gradient = np.zeros((self.output.shape[0], self.input.shape[0]), dtype = np.float64)\n",
        "        for b in range(output_gradient.shape[1]):\n",
        "          dense_gradient += np.dot(output_gradient[:, b].reshape(-1, 1), self.input[:, b].reshape(-1, 1).T)\n",
        "        dense_gradient = (1/output_gradient.shape[1] * dense_gradient)\n",
        "        ## Following is the efficient way of calculating the backward gradient\n",
        "        #dense_gradient = (1/output_gradient.shape[1])*np.dot(np.atleast_2d(output_gradient), np.atleast_2d(self.input).T)\n",
        "        self.weights = self.weights + learning_rate * (-dense_gradient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W1howeOJegI"
      },
      "source": [
        "---\n",
        "\n",
        "Function to generate sample indices for batch processing according to batch size\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MHyjEf22IRpc"
      },
      "outputs": [],
      "source": [
        "## Function to generate sample indices for batch processing according to batch size\n",
        "def generate_batch_indices(num_samples, batch_size):\n",
        "  # Reorder sample indices\n",
        "  reordered_sample_indices = np.random.choice(num_samples, num_samples, replace = False)\n",
        "  # Generate batch indices for batch processing\n",
        "  batch_indices = np.split(reordered_sample_indices, np.arange(batch_size, len(reordered_sample_indices), batch_size))\n",
        "  return(batch_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKFmCaFsJhkR"
      },
      "source": [
        "---\n",
        "\n",
        "Example generation of batch indices\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "k9QwikN0IYSp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([37, 52, 58, 25, 30, 50, 10, 13]), array([ 7, 38,  8, 48, 40, 26, 24, 15]), array([14, 62, 55, 34, 23, 21, 11, 44]), array([28, 60, 54,  4, 41,  6, 33, 49]), array([ 3,  2, 45, 35, 36, 27, 16, 51]), array([61, 59, 31, 53, 47, 18, 63, 46]), array([32, 19, 22, 43, 12,  5, 42, 56]), array([ 1, 39,  9, 29,  0, 57, 20, 17])]\n"
          ]
        }
      ],
      "source": [
        "## Example generation of batch indices\n",
        "num_samples = 64\n",
        "batch_size = 8\n",
        "batch_indices = generate_batch_indices(num_samples, batch_size)\n",
        "print(batch_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI_Gms9fJqbs"
      },
      "source": [
        "---\n",
        "\n",
        "Train the 0-layer neural network using batch training with batch size = 16\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LGIzrN-rPuI4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss = 2.295188\n",
            "Epoch 2: loss = 2.275155\n",
            "Epoch 3: loss = 2.255539\n",
            "Epoch 4: loss = 2.236321\n",
            "Epoch 5: loss = 2.217483\n",
            "Epoch 6: loss = 2.199008\n",
            "Epoch 7: loss = 2.180882\n",
            "Epoch 8: loss = 2.163089\n",
            "Epoch 9: loss = 2.145615\n",
            "Epoch 10: loss = 2.128447\n",
            "Epoch 11: loss = 2.111573\n",
            "Epoch 12: loss = 2.094982\n",
            "Epoch 13: loss = 2.078661\n",
            "Epoch 14: loss = 2.062600\n",
            "Epoch 15: loss = 2.046791\n",
            "Epoch 16: loss = 2.031222\n",
            "Epoch 17: loss = 2.015887\n",
            "Epoch 18: loss = 2.000776\n",
            "Epoch 19: loss = 1.985882\n",
            "Epoch 20: loss = 1.971197\n"
          ]
        }
      ],
      "source": [
        "## Train the 0-layer neural network using batch training with batch size = 16\n",
        "learning_rate = 1e-2 # learning rate\n",
        "batch_size = 200 # batch size\n",
        "nepochs = 20 # number of epochs\n",
        "loss_epoch = np.empty(nepochs, dtype = np.float32) # create empty array to store losses over each epoch\n",
        "\n",
        "# Neural network architecture\n",
        "dlayer = Dense(num_features, num_labels) # define dense layer\n",
        "softmax = Softmax() # define softmax activation layer\n",
        "\n",
        "# Steps: run over each sample in the batch, calculate loss, gradient of loss,\n",
        "# and update weights.\n",
        "\n",
        "epoch = 0\n",
        "while epoch < nepochs:\n",
        "  batch_indices = generate_batch_indices(num_samples, batch_size)\n",
        "  loss = 0\n",
        "  for b in range(len(batch_indices)):\n",
        "    dlayer.forward(X_train[:, batch_indices[b]]) # forward prop\n",
        "    softmax.forward(dlayer.output) # Softmax activate\n",
        "    loss += cce(Y_train[:, batch_indices[b]], softmax.output) # calculate loss\n",
        "    # Backward prop starts here\n",
        "    grad = cce_gradient(Y_train[:, batch_indices[b]], softmax.output)\n",
        "    grad = softmax.backward(grad)\n",
        "    grad = dlayer.backward(grad, learning_rate)\n",
        "  loss_epoch[epoch] = loss/len(batch_indices)\n",
        "  print('Epoch %d: loss = %f'%(epoch+1, loss_epoch[epoch]))\n",
        "  epoch = epoch + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Iv3k23SlCqGf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABQx0lEQVR4nO3dd1QU5xoG8GfpggtGUVCMSFRsKJZYiIrdaGLvHRULltiw4E0ilqiJCqKIJRbEhhoV1CRYY6ImIDExisaSIFgoawFdlA7f/cPr3hABWQRmy/M75z3H3f1mfGbHzbz5dmZHBkCAiIiISI8YSB2AiIiIqKyxASIiIiK9wwaIiIiI9A4bICIiItI7bICIiIhI77ABIiIiIr3DBoiIiIj0jpHUATRVtWrVkJKSInUMIiIiUoNcLkd8fPwbx7EByke1atUQFxcndQwiIiIqBjs7uzc2QWyA8vFq5sfOzo6zQERERFpCLpcjLi6uSMduNkCFSElJYQNERESkg3gSNBEREekdNkBERESkd9gAERERkd5hA0RERER6hw0QERER6R1JGyAvLy9ERkZCqVRCoVAgJCQEjo6OhS7Tr18//Prrr0hOTsbz589x+fJljBw58rVxixcvRnx8PFJTU3Hq1CnUrl27tDaDiIiItIykDVD79u0REBCA1q1bo2vXrjA2NsbJkydhbm5e4DJJSUlYtmwZXFxc0LhxYwQGBiIwMBDdunVTjZk3bx6mT58ODw8PtGrVCi9evMCJEydgampaFptFREREWkBoSllbWwshhGjXrp1ay/32229iyZIlqsfx8fHC09NT9djS0lKkpaWJIUOGFGl9crlcCCGEXC6X/D1hsVgsFotVtFLn+K1R5wBZWVkBeDnLU1SdOnVC3bp1ce7cOQCAg4MDqlatitOnT6vGKJVKXLx4ES4uLvmuw8TEBHK5PE8RERGR7tKYX4KWyWTw8/PDhQsXcP369ULHWlpaIi4uDqampsjJycGUKVNUDY+trS0AQKFQ5FlGoVCoXvu3BQsWYNGiRW+/EURERKQVNKYBCggIgJOTE9q2bfvGsSkpKWjSpAnKly+Pzp07w9fXF3fu3MFPP/1UrL97xYoV8PX1VT1+dS8RIiIi0k0a0QD5+/ujZ8+ecHV1LVLjIYRAdHQ0AODKlSuoX78+FixYgJ9++gmJiYkAABsbG9WfXz3+448/8l1fZmYmMjMz335DiIiISCtIfg6Qv78/+vXrh06dOiE2NrZY6zAwMFBd4RUTE4OEhAR07txZ9bpcLkerVq0QHh5eEpHfSoP2bSGTyaSOQUREpPckO1s7ICBAJCcnC1dXV2FjY6MqMzMz1ZigoCCxfPly1WMvLy/RpUsX4eDgIOrVqydmz54tMjMzhbu7u2rMvHnzRFJSkujVq5dwcnISISEhIjo6Wpiampb4WeTqlOvoocInKlyM+GqxMDQ2lvxseRaLxWKxdKnUOX5L+hXYlClTAOC1c3fGjBmDoKAgAECNGjWQm5ures3CwgIbNmxA9erVkZaWhps3b2LkyJE4cOCAaszKlSthYWGBr7/+GhUqVMCFCxfQvXt3ZGRklMFWFSz1qRI5Wdlo9lE3WFa2xo6ZXkhTpkiaiYiISB/J8LITon+Qy+VQKpWwtLRESkrJNih1WrfAmDUrYFbeAonRMdg6ZTaS4xPfvCAREREVSp3jt+TnAOmbvyJ+xXq3SXiqeAjbWg6YvnsLqjeoK3UsIiIivcIGSAIJt6OxbsR4xN/6C5aVrTElcAPqtcv/RxqJiIio5LEBksgzxSOsd/PArV8uwtTcHO7+q9B6YB+pYxEREekFNkASyniRiq1TPREZ+i0MDA0xyNsLPaZ78DJ5IiKiUsYGSGK52TnY//kynAjYAgDoMsENw1d4w9DYWOJkREREuosNkIY4uWk79n229OVl8h9/iImb/VDOkjdlJSIiKg1sgDTIr0e+x9aps5H+/AVqt2iGaTs3452q+d/AlYiIiIqPDZCGuR3+r8vk92yBXX1HqWMRERHpFDZAGkh1mfztv2FZ2RpTd2zkZfJEREQliA2QhnqmeIQANw/cDo+Eqbk5xq1bycvkiYiISggbIA2W/vwFtkyZjcjQb2FoZPTyMvlPJkkdi4iISOuxAdJwqsvkN2wFAHSZOAYjvlzEy+SJiIjeAhsgLXFy4zbs+/yL/18mv2kNL5MnIiIqJjZAWuTX0O+wdarny8vkWzbHtKBNvEyeiIioGNgAaZnb4ZFY7+bx8jL52u/xMnkiIqJiYAOkhRJu//36ZfJtW0sdi4iISGuwAdJSr10m778KrQb0ljoWERGRVmADpMXSn7/A1ime+PXIdzA0MsLgRQt4mTwREVERsAHScjnZ2dj32Rd5L5P/ajGMTEwkTkZERKS52ADpiDyXyX/UDR5b1sHinQpSxyIiItJIbIB0yK+h32HL5FlIU6bAoZkzpu/egso1a0gdi4iISOOwAdIxf128hHUjJ+DJgzhY16iO6bu3oNb7TaWORUREpFHYAOmghzF3sW7EBMReiYK5lSUmfr0WzXv1kDoWERGRxmADpKOeJyVjo/sn+OP4aRgZG2P48oX4cOoEqWMRERFpBDZAOiw7IwO75y3E6S1BAIBuHuN4hRgRERHYAOk8IQTC1m3C/s+X5b1CrIKV1NGIiIgkwwZIT0SGfpv3CrE9W3mFGBER6S02QHrk/1eIxfMKMSIi0mtsgPTMyyvExvMKMSIi0mtsgPSQ6gqxE2d4hRgREeklNkB6KjsjA7vnfs4rxIiISC+xAdJjvEKMiIj0FRsg4hViRESkd9gAEYCXV4j5j5qY5wqx93iFGBER6Sg2QKSiuBOb5wqxSbxCjIiIdBQbIMqDV4gREZE+YANEr8n3CrEvF/EKMSIi0hlsgChfr10h9vGHvEKMiIh0BhsgKlR+V4hVcbCXOhYREdFbYQNEb5TfFWKOLi2kjkVERFRsbICoSBR3YrF2uDtifr+CcpZyjN/giw+G9Jc6FhERUbFI2gB5eXkhMjISSqUSCoUCISEhcHR0LHSZ8ePH49y5c0hKSkJSUhJOnTqFFi3yzkYEBgZCCJGnwsLCSnNT9MKL5KfYOP4TXDoaBkMjIwz4bC76LZgNA0NDqaMRERGpRdIGqH379ggICEDr1q3RtWtXGBsb4+TJkzA3Ny9wmQ4dOiA4OBgdO3aEi4sL7t+/j5MnT6JatWp5xoWFhcHW1lZVw4YNK+3N0Qs5WVkI/nQJvvPbCABoO3wQ3Nevhll5C4mTERERqUdoSllbWwshhGjXrl2RlzEwMBDPnj0To0aNUj0XGBgoQkJCip1DLpcLIYSQy+WSvyeaXI06txfLL/4gfKLCxdzQvaJi9WqSZ2KxWCyW/pY6x2+NOgfIysoKAJCUlFTkZczNzWFsbPzaMh06dIBCocDNmzexYcMGVKxYscB1mJiYQC6X5yl6s6gzPyFgjAeeKh7CtpYDZu7dBodmzlLHIiIiKhLJOzYAQiaTiWPHjonz58+rtVxAQID4+++/hampqeq5IUOGiF69egknJyfRp08fcf36dXHx4kVhYGCQ7zq8vb1FfjgDVLSyrGwtZu7bLnyiwsVXv58TLfp8JHkmFovFYulfqfkNjvSBAYgNGzaImJgYYWdnV+Rl5s+fL548eSIaNWpU6DgHBwchhBCdOnXK93UTExMhl8tVVa1aNTZAapaxmakY7bNM+ESFC5+ocPHxrClCJpNJnovFYrFY+lNa1wD5+/uLe/fuiZo1axZ5GU9PT5GcnCyaN29epPEPHz4UEydOLI03kPW/kslkovu0iaomaOzaL4VJuXKS52KxWCyWfpRWNUD+/v7iwYMHonbt2kVeZu7cueLp06eiVatWRRpvZ2cncnJyRK9evUrjDWT9q5p93E18eelH4RMVLmYfCBIVbKpInonFYrFYul9a0wAFBASI5ORk4erqKmxsbFRlZmamGhMUFCSWL1+uejxv3jyRnp4u+vfvn2cZCwsLAUBYWFiIlStXilatWgl7e3vRqVMncenSJXHr1i1hYmJSGm8gK5+yd3YSi378TvhEhQvvH46Jd50aSJ6JxWKxWLpdWtMAFcTNzU015uzZsyIwMFD1OCYmJt9lvL29BQBhZmYmjh8/LhQKhcjIyBAxMTFi8+bNokqVos9CsAEqmXqnqq2Yc3i38IkKF1/++qNo8mFnyTOxWCwWS3dLneO37H9/oH+Qy+VQKpWwtLRESkqK1HG0mqm5OUauXIIG7dsAAI4HbMGpTdslTkVERLpIneO3Rv0OEOmejNRUbJ8+Dz8G7QUAdJ86ASO+WgwjU1OJkxERkT5jA0SlTuTm4thqfxzwXo6crGw0+6gbpmxbD3mlgn+ckoiIqDSxAaIyc/HwMWyeNAOpz5Swd3bCjOBtqOpYW+pYRESkh9gAUZmK/vV3rB3ujocxd/FOVVt8smszGnZoK3UsIiLSM2yAqMw9vvcA60ZOwO2IX2Fqbo4xa79CB7fhUsciIiI9wgaIJJGmTMGWybPwy/7DMDAwQK85n2Dw4v/A0MhI6mhERKQH2ACRZHKzc3Doi1UIWeGL3JwctOrfC5O2rIPFOxWkjkZERDqODRBJ7sLeb7Bt2hykP3+BWu83xYy921DVsZbUsYiISIexASKNcPNCBNYOd8fjew9QqXo1fLLrazh1cpU6FhER6Sg2QKQxHsbchd8wd9XJ0WPXfoUuE8dIHYuIiHQQGyDSKGlKJbZMnoXzew4AAHp8MgkjVy6BsRl/OZqIiEoOGyDSOLnZOQj9cg0OLFqBnKxsNO3RFVN3bISVTWWpoxERkY5gA0Qa6+Kho9g04RM8T0rGuw3rY+a+QNRo3FDqWEREpAPYAJFGu/PbH/AbNg7xt/+GpXUlTA3cgOa9ekgdi4iItBwbINJ4yfGJ8B85EVFnfoKRiQmGL1+InrOnQWbAf75ERFQ8PIKQVshMS0PQrAU4tTkQANBx7Ai4r18Fs/IWEicjIiJtxAaItIYQAsfXf41dcz5DZlo66rf7ADP2boN1jepSRyMiIi3DBoi0zh8nziBgjAeeJipQxcEeM4K3wdGlhdSxiIhIi7ABIq304M9b8Bs6DrFXomBuaYnxG3zRdvggqWMREZGWYANEWivlSRI2jpuGX498D0MjI/RbMBuDFy3gHeWJiOiN2ACRVsvOzMS+z5bi6Kp1L+8oP6A3PLb6o3zFd6SORkREGowNEOmEn3YGY9u0OUhLeY73mjfBjOBtqOpYW+pYRESkodgAkc64eSEC60aMx6O791GxWlV8sutrNOrcXupYRESkgdgAkU55GHMXa4e743Z4JEzNy2GM35fo6jFO6lhERKRh2ACRzklTpmDL5Nk4t3s/AKD71AkYtfoLmJQzkzgZERFpCjZApJNyc3Jw5Cs/HPBejuysLDT5sDOm7tiECrY2UkcjIiINwAaIdNrFw8ewafwnSHmShOoN6mLmvu14r3kTqWMREZHE2ACRzov5/QrWDnNH3I3bkFeqCI8t/vhgSH+pYxERkYTYAJFeSE5IhP/oibgcdgqGxkYY8NlcDPL2gqGxsdTRiIhIAmyASG9kpWdg97yF+HZNAHJzc9F6YB9M2R4AuXUlqaMREVEZYwNEeufs9t3YOsUTqUolajZphFn7AlGjUQOpYxERURliA0R66dbPEVg7zB2Jf9+BlU1lTN2xES36fCR1LCIiKiNsgEhvPb73AOtGTMC1H36CkYkJhn7xOfrMnwkDI0OpoxERUSljA0R6LSM1FTtmLsCJgC0AANeRQzBxkx8s3qkgbTAiIipVbIBI7wkhcHLTdgTOmI/0Fy9Qp9X7mBm8HdXq1pE6GhERlRI2QET/c+2Hc1g3YsLLm6navbyZapPuXaSORUREpYANENE/KKJjsHa4O25eiIBJOTOMWrUUH8+aApkBPypERLqE/1Un+pc0ZQq2TvXED9t3AQA6jRsF94DVKGcplzgZERGVFDZARPkQubn4bs0G7J63EJlp6ajf1gUz9m6DzXs1pY5GREQlgA0QUSEuh53C+tGTkBSfgMr272L63q1o2LGd1LGIiOgtsQEieoO4m7fhN3Qc/o78DWYWFhi3biW6eYyDTCaTOhoRERWTpA2Ql5cXIiMjoVQqoVAoEBISAkdHx0KXGT9+PM6dO4ekpCQkJSXh1KlTaNGixWvjFi9ejPj4eKSmpuLUqVOoXbt2aW0G6YEXyU+xedIMnN9zAADw4dQJcFuzAqbm5hInIyKi4pC0AWrfvj0CAgLQunVrdO3aFcbGxjh58iTMCzmodOjQAcHBwejYsSNcXFxw//59nDx5EtWqVVONmTdvHqZPnw4PDw+0atUKL168wIkTJ2BqaloWm0U6Kjc7B6FfrsG+z79AdmYmGnVuj+l7tqDSu9WljkZERMUgNKWsra2FEEK0a9euyMsYGBiIZ8+eiVGjRqmei4+PF56enqrHlpaWIi0tTQwZMqRI65TL5UIIIeRyueTvCUszq0bjhmLhmaPCJypcLP35hKj7QSvJM7FYLJa+lzrHb406B8jKygoAkJSUVORlzM3NYWxsrFrGwcEBVatWxenTp1VjlEolLl68CBcXl3zXYWJiArlcnqeICnPv6nWsGTIWsVeiYG5pifEbfNBhzAipYxERURFpTAMkk8ng5+eHCxcu4Pr160Ve7quvvkJ8fLyq4bG1tQUAKBSKPOMUCoXqtX9bsGABlEqlquLi4oq5FaRPUh4/wYaxU3Hx0FEYGBqil+c0jFq1FCblykkdjYiI3kBjGqCAgAA4OTlh6NChRV5m/vz5GDp0KPr164eMjIxi/90rVqyApaWlquzs7Iq9LtIvOVlZOLBoBQ59sQo5Wdlo0r0LzwsiItICGtEA+fv7o2fPnujYsWORZ188PT3h5eWFbt26ISoqSvV8YmIiAMDGxibPeBsbG9Vr/5aZmYmUlJQ8RaSOX/YfxoZxU6F89BhV69TCrH3bUb/dB1LHIiKiQkh6wpK/v7948OCBqF27dpGXmTt3rnj69Klo1Sr/E0/j4+PF7Nmz85wUxZOgWWVRlpWtxbSdm4VPVLhYdeVn0dVjnJDJZJLnYrFYLH0oNY/f0gUNCAgQycnJwtXVVdjY2KjKzMxMNSYoKEgsX75c9XjevHkiPT1d9O/fP88yFhYWecYkJSWJXr16CScnJxESEiKio6OFqalpabyBLFaeMjQyEv0/nSN8osKFT1S4GLdupTArbyF5LhaLxdL10poGqCBubm6qMWfPnhWBgYGqxzExMfku4+3tnWfdixcvFgkJCSItLU2cOnVK1KlTp7TeQBYr32rR92Px5aUfhU9UuPA6tl/Y1HKQPBOLxWLpcqlz/Jb97w/0D3K5HEqlEpaWljwfiN5K9Qb1MMZvBd6paouM1FTs++wLXD11VupYREQ6SZ3jt0acBE2kqx78eRNrhozFXxGXYGpuDjff5fh45mTIDPjRIyKSEv8rTFTKXiQ/xdceM3E2cA8AoJP7aEzctAbmVpYSJyMi0l9sgIjKQG5ODr71XY9dcz5DRmoaHF1aYtb+HbCrX/jNf4mIqHSwASIqQ3+cOIN1Iyfg8b0HqGhXFZ/s/BrNe/WQOhYRkd5hA0RUxhL/iobfsHH489zPMDYzxfDlC9FvwWwYGBlKHY2ISG+wASKSQJoyBdunzcXJjdsAAG2HD8Lkreshr1RR4mRERPqBDRCRRIQQOLFhK7Z/MhdpKc/xXvMmmLV/B+ydnaSORkSk89gAEUns+o8XsHa4OxKjY2BlUxlTAjeg9aC+UsciItJpbICINMCj2HtYN3w8rpz8AUbGxhi0cD4GL/4PjExMpI5GRKST2AARaYiM1FTs9PwU364JQG5ODlr174WpOzaigk0VqaMREekcNkBEGubs9t3YMnkWXjx9hhqNGmDm/kDUer+p1LGIiHQKGyAiDXQ7/Ff4DR2LuBu3Ia9UEZO2rIPr6KFSxyIi0hlsgIg0VFJcAvxHT8SlY2EwNDJCn7kzMGr1FzA1N5c6GhGR1mMDRKTBstIzEPyfJTi83Ac5Wdlo8mFnzAjehioO9lJHIyLSamyAiLTAz8EHETB2Mp4pHsHmvZqYEbwNjbt1kjoWEZHWYgNEpCXuXrkG3yFu+DvyN5hZWMDNZxl6z53OW2gQERUDGyAiLfL8STI2T5yBH7btBAC0Hz0MHlv9IbeuJHEyIiLtwgaISMvk5uTgO7+NCJwxH2kpz1GreVPMPrADDs2cpY5GRKQ12AARaalrP5yD37BxSPgrGpaVrTF523peKk9EVERsgIi02OO797FuxHj8/t0JXipPRKQGNkBEWi4zLR17vBbh8HIfZGdl8VJ5IqIiYANEpCN+Dj6IDWOn4KniIS+VJyJ6AzZARDrk7pVrWDN4DP66eImXyhMRFYINEJGOeZ6UjK8nzeSl8kREhWADRKSDeKk8EVHh2AAR6bBrP5yD39CxvFSeiOhf2AAR6bjH9x5g3Yjx+O3b47xUnojof9gAEemBzLR07F2wGIeXreal8kREKGYDNHLkSFy4cAFxcXGoUaMGAGDGjBno3bt3iYYjopL1875DvFSeiAjFaIA8PDzg6+uL77//HhUqVICh4cvLa58+fYqZM2eWdD4iKmGqS+UjeKk8Eek3oU5dv35d9OnTRwAQSqVSODg4CACiYcOG4tGjR2qtS1NLLpcLIYSQy+WSZ2GxSqsMDA3FRzMmC5+ocOETFS6mBW0SllUqS56LxWKxilvqHL/VngFycHDA5cuXX3s+IyMDFhYW6q6OiCSSm5OD79f+/1J5h2bOmH1gB+q0biF1NCKiUqd2AxQTE4MmTZq89nz37t1x48aNkshERGXo2g/nsGbIWMTduA15pYqYuNkPXSaNhUwmkzoaEVGpUbsB8vX1RUBAAAYPHgyZTIaWLVviP//5D1asWIGVK1eWRkYiKmVP7j/AulETEXHwCAwMDNBj2kSM3+ALiwpWUkcjIio1an/HNnz4cHH79m2Rk5MjcnJyxP3798W4ceMk/+6vpIrnALH0ud7v/ZFYEXlW+ESFi89PhQp7ZyfJM7FYLFZRSp3jt+x/fyiWcuXKoXz58nj06FFxV6GR5HI5lEolLC0tkZKSInUcojJnW6cW3HyWoYqDPXKysnHMxx/n9xyQOhYRUaHUOX6/1Q8hpqWl6VzzQ0RA4l/R8Bs6Dn8cPw1DYyP09ZqF0T7LYGrBX48mIt2g9gzQnTt3IETBi9SqVettM0mOM0BE/9dm2ED0njsdRsbGeHT3PoJm/wcJt/+WOhYR0WvUOX4bqbtyPz+/PI+NjY3RtGlTdO/eHatWrVJ3dUSk4X4OPoj71/7EqNVfoLL9u5ixZysOL1uNyNBvpY5GRFRsb3UO0D9NmTIF77//PsaNG1cSq5MUZ4CIXmduZYnhK7xRv90HAIDIkG9xePlqZKVnSJyMiOgldY7fJdYAOTg44I8//oCVlVVJrE5SbICI8ieTydDJfTS6T5sAA0NDxN/+G0Gz/4PHd+9LHY2IqOxOgv6ngQMHIikpSa1lvLy8EBkZCaVSCYVCgZCQEDg6Oha6TIMGDXDw4EHExMRACIEZM2a8Nsbb2xtCiDzFH2kkentCCJzZGoRNE6Yj5UkSqjnWxqx9gbyhKhFpHbXPAfr999/znAQtk8lga2uLypUrY8qUKWqtq3379ggICMCvv/4KIyMjLF++HCdPnkSDBg2Qmpqa7zLm5ua4c+cOvvnmG6xZs6bAdV+7dg1dunRRPc7OzlYrGxEVLPrX3+E7yA0jVy1BreZN4eazDOd27ce3vuuRw88aEWkBtRug0NDQPI9zc3Px6NEj/Pjjj7h165Za6+rRo0eex2PGjMGjR4/QvHlznD9/Pt9lLl26hEuXLgEAvvzyywLXnZ2dDYVCUaQcJiYmMDU1VT2Wy+VFWo5InykfPcYm90/Q45OJ6OQ+Gq6jhqBG4wbYNedzPE0s2mePiEgqajdAS5YsKY0cAKA6f0jdr9LyU6dOHcTFxSE9PR3h4eFYsGAB7t/P/zyFBQsWYNGiRW/9dxLpm9ycHHzntxGxf0Rh6LLPUdO5EWZ/E4Q9Xotw6+cIqeMRERWoSCdBqzMjUtyThmUyGY4ePYoKFSqgXbt2RVomJiYGfn5+WLt2bZ7nu3fvjvLly+PWrVuoWrUqvL29YWdnBycnJzx//vy19eQ3AxQXF8eToInUUNGuKkb7LMO7DesjNzcXZ7YE4cSGrRC5uVJHIyI9oe5FTG+8X0ZOTo7Izs4utF6NKcr68qsNGzaImJgYYWdnV+RlYmJixIwZM944zsrKSjx9+rTI9yvjvcBYrOKVkYmJ6P/pHOETFS58osLFpC3rRPlK70iei8Vi6Uepc/wu0ldgHTt2LMqwYvP390fPnj3h6uqKuLi4El//s2fPcPv2bdSuXbvE101E/5edmYnDy1Yj5vJVDPL2gmPrFph9IAi75n6OmN+vSB2PiEilSA3QuXPnSi2Av78/+vXrhw4dOiA2NrZU/g4LCwvUqlULu3btKpX1E1Fel78/ifibtzHadzlsazlg8rb1CPPfjB8D9xR6Kx0iorJS7N8BKleuHOrWrYtGjRrlKXUEBARg5MiRGD58OFJSUmBjYwMbGxuYmZmpxgQFBWH58uWqx8bGxnB2doazszNMTExgZ2cHZ2fnPPcgW7VqFVxdXWFvbw8XFxeEhIQgJycHwcHBxd1cIlKT4k4s1g5zx2/fHoehkRF6zpqKcetXwaKCldTRiIgAqPn9mrW1tTh27FiB5wKps66CuLm5qcacPXtWBAYGqh7b29vnu8zZs2dVY4KDg0VcXJxIT08X9+/fF8HBweK9994rle8QWSzWm6vVgN7iy0s/Cp+ocPH5qVBRs0ljyTOxWCzdKzWP3+qtfPfu3eL8+fOiefPmIiUlRXTp0kWMGDFC3LhxQ3z00UeSb7wEbyCLxSpCVXWsLeYf3Sd8osLFysvnRcexI4RMJpM8F4vF0p0q1QYoPj5etGjRQgAQz549E3Xq1BEARK9evcT58+cl33gJ3kAWi1XEMjU3FyO+Wqy6Ssw9YLWwqGAleS4Wi6Ubpc7xW+1zgCwsLPDw4UMAQHJyMipXrgwAiIqKQrNmzdRdHRHpkYzUVOyZ741vFn+JrIwMNHBtg9nfBKFmk8ZSRyMiPaN2A3Tr1i3UrVsXAHDlyhVMmjQJ1apVg4eHBxISEko8IBHpnoiDR7B2+Hg8jLmLCrY2mBIYgI5jR0Amk0kdjYj0RJF+CfqfRowYASMjIwQFBaFZs2Y4fvw4KlasiMzMTIwZMwYHDhwopahlR91fkiSi4jE1N8dA7/lo9lE3AMCf537Gvk+X4sXTZxInIyJtpM7xW+0G6N/KlSuHevXq4d69e3jy5MnbrEpjsAEiKlutB/ZBX69ZMDY1xdNEBXbNXYjYP65KHYuItIw6x2+1vwJr06ZNnsdpaWm4fPmyzjQ/RFT2Xn0l9ij2Hr8SI6IyoXYD9MMPP+DOnTtYtmwZ6tevXxqZiEgPJdz+G2uGjMXv3598+cOJs6dhnP8qmFtZSh2NiHSQ2g1QtWrV4OPjg/bt2+PatWu4fPky5syZAzs7u9LIR0R65LWrxNq3gefBnajprN6vzBMRvclbnQNUs2ZNDB8+HMOGDUO9evVw7tw5dO7cuQTjSYPnABFJr6pjbbj5LEPlmjWQk52NsHWb8OOOvbyXGBEVqExPgjYwMECPHj2wdOlSNG7cGEZGRbq/qkZjA0SkGUzNzTHIez6avrpK7KefEfzpEqQ+U0qcjIg0UameBP3KBx98gICAACQkJGDv3r24du0aPv744+KujojoNRmpqdjNr8SIqJSo9TPTy5cvF3fu3BHp6eni2LFjYujQoaJcuXKS//x1SRZvhcFiaV5VdawtvI7tV91LrMMY3kuMxWLlLXWO32p/BXbhwgXs2bMHBw4c0NlL3/kVGJFm4ldiRFSYMj0HSBexASLSbK/9cOKczxF7JUrqWEQksTI5B4iISCoRB49g3YgJ///hxB0b0Ml9FH84kYiKjA0QEWml+Ft/5fnhxI9nTsGEjb4oX+kdqaMRkRZgA0REWuvVDyce8F6OzLR01G3TGp7f7ESdVu9LHY2INBwbICLSehcPH4PfsHFI+CsalpWtMfHrtej+yUQYGBpKHY2INJTaDVD16tXz3PaiRYsWWLNmDSZMmFCiwYiI1KGIjsHa4e4IPxgKAwMDdJ04FlO2B6CCrY3U0YhIA6ndAO3duxcdO3YEANjY2ODUqVNo2bIlli1bhs8//7zEAxIRFVVWegYOLv4Ku+Z8hvTnL+DQzBmeB3eiYcd2UkcjIg2jdgPk5OSEyMhIAMDgwYNx7do1tGnTBiNGjMCYMWNKOh8Rkdr+OHEGvoPccO/anzC3ssS4dSvR12sWDI2NpY5GRBpC7QbI2NgYGRkZAIAuXbrg6NGjAICbN2+iatWqJZuOiKiYnjyIw/pRk/Bj0F4AQLsRgzF99xZY16gucTIi0gRqN0DXr1+Hh4cH2rZti65du+L48eMAgGrVqunsL0MTkXbKyc7GsdX+2DrFEy+Sn6J6g7qYdWAHmn3cTepoRCQxtRug+fPnY9KkSfjxxx8RHByMq1evAgB69+6t+mqMiEiT3Dj/C3wGjUb0pcsws7DAiC8XY8iST2FSzkzqaEQkkWLdCsPAwACWlpZ4+vSp6jl7e3ukpqbi0aNHJRhPGrwVBpFukhkYoOuksejqMQ4GBgZQ3InFrrmfIeF2tNTRiKgElOqtMMzMzGBqaqpqfmrUqIEZM2agbt26OtH8EJHuErm5OLlxGza5T8MzxSPYvFcTM/Zug8ugflJHI6IypnYDdOTIEYwePRoAYGVlhYsXL8LT0xOhoaHw8PAo8YBERCUt+tJl+AwajT/P/QxjU1MMXDgPo32WwUxeXupoRFRG1G6AmjVrhvPnzwMABg4cCIVCAXt7e4wePRrTp08v8YBERKXhRfJTbJ82F0dXrUNOVjacu3XC7ANBqNGogdTRiKgMqN0AmZubq75X69atGw4fPgwhBCIiImBvb1/iAYmISosQAj/tDIb/6El48iAOlapXw7SgzegwZgTvLE+k49RugP7++2/07dsX1atXx4cffoiTJ08CAKpUqQKlUlniAYmIStv9a3/Cd5Ab/jhxBobGRujlOQ3uG3xQviLvLE+kq9RugJYsWYLVq1cjNjYWkZGRiIiIAPByNujy5cslHpCIqCykP3+BXXM+wzeLv0RWegbqt3XB7G+CULtlc6mjEVEpKNZl8DY2NqhatSquXLkCIV4u3qJFCyiVSty6daukM5Y5XgZPpN9s69TCqFVLYVvLAbm5uTj99Q6c2rQduTk5UkcjokKoc/wuVgP0yqu7wsfFxRV3FRqJDRARmZQzQ9/5s9BqQG8AQMzlq9gz3xvJCYkSJyOigpTq7wDJZDJ8/vnnePr0Ke7evYu7d+8iOTkZn332GU8aJCKdkZmWjgOLVmD3vIVIS3kOh6aN4XlwJxp36yR1NCIqIUKdWr58uVAoFMLDw0M0atRINGrUSEyePFkoFArxxRdfqLUuTS25XC6EEEIul0uehcViSV8V7aqKT3Z/LXyiwoVPVLgY5O0lTMqZSZ6LxWLlLTWP3+qtPC4uTvTq1eu153v37i0ePHgg+cZL8AayWCw9KAMjQ9Hjk0li1ZWfhU9UuJh3JFhUdawteS4Wi/X/Uuf4rfZXYBUrVsTNmzdfe/7mzZuoWLGiuqsjItIKudk5CPPfjM0TpqtuozEzeBvaDh8kdTQiKga1G6ArV65g2rRprz0/bdo0XLlypURCERFpqr8jf4PPwFG4fvY8jExM0G/BbLivXw2LdypIHY2I1KD2VWCurq747rvvcO/ePYSHhwMAXFxc8O677+Kjjz7ChQsXSiNnmeJVYERUFG2GDUQvz2kwNjXFs4ePEPzpUvwV8avUsYj0VqlfBl+1alVMnToV9erVAwDcuHEDGzZsQEJCQrECaxo2QERUVFUda2HkV0tgW/s95Obm4sfA3Qhb/zVys/mbQURlrcx+B+if7OzssHDhQkyaNKkkVicpNkBEpA5jM1P0njsDHwzuBwC4F/Unds9biCcPdOs30og0Xan+DlBBKlWqBHd3d7WW8fLyQmRkJJRKJRQKBUJCQuDo6FjoMg0aNMDBgwcRExMDIQRmzJiR77gpU6YgJiYGaWlpiIiIQIsWLdTKRkRUVFnpGTi0dCV2zPRCqlKJGo0aYPY3QWj2cTepoxFRAUqsASqO9u3bIyAgAK1bt0bXrl1hbGyMkydPwtzcvMBlzM3NcefOHXh5eRX4ldvgwYPh6+uLxYsXo1mzZrhy5QpOnDiBypUrl9amEBEh6sxP8BkwGtG/XYZZeQuM+HIxhi1bCNNC/ptGRNIpkWvvGzduLLKzs99qHdbW1kIIIdq1a1ek8TExMWLGjBmvPR8RESH8/f1Vj2UymXjw4IGYP39+vusxMTERcrlcVdWqVePvALFYrGKXgaGh6OYxTqz644LwiQoXXt8eENUb1JM8F4ul61WqvwNUmqysrAAASUlJxV6HsbExmjdvjtOnT6ueE0Lg9OnTcHFxyXeZBQsWQKlUqkrX7m1GRGUrNycHJzdtx4axU5CckIjK9u9i+u4t6DBmBG8ZRKQhjIo68NChQ4W+XqFChbcKIpPJ4OfnhwsXLuD69evFXo+1tTWMjIygUCjyPK9QKFRXrf3bihUr4Ovrq3osl8vZBBHRW4u5fBU+A0djkLcXnLt1Qi/PaXB0aYHg/yxBypPi/48eEb29IjdAz549e+PrO3fuLHaQgIAAODk5oW3btsVeR3FlZmYiMzOzzP9eItJ9acoU7PT8FK3690Jfr9mo+0EreB7ahX2fLcXNCxFSxyPSW0VugMaNG1dqIfz9/dGzZ0+4urq+9czL48ePkZ2dDRsbmzzP29jYIDEx8a3WTURUXBcPH0PM5asYtWopqtWtgwkb1+CnncH4zm8jcrKypI5HpHckPwfI398f/fr1Q6dOnRAbG/vW68vKysJvv/2Gzp07q56TyWTo3Lmz6periYik8DDmLtYOH49zu/cDANqPHobpu7egcs0aEicj0j+SNkABAQEYOXIkhg8fjpSUFNjY2MDGxgZmZmaqMUFBQVi+fLnqsbGxMZydneHs7AwTExPY2dnB2dkZtWrVUo3x9fXFhAkTMHr0aNSrVw8bN26EhYUFAgMDy3T7iIj+LTszE0e+8sO2aXPxIvkpqjeoi1n7d6DVgN5SRyPSO5JdrlYQNzc31ZizZ8+KwMBA1WN7e/t8lzl79myedU+dOlXExsaK9PR0ERERIVq2bFkql9GxWCxWccuysrWYtGWd8IkKFz5R4cJtzQphbmUpeS4WS1tLneN3id0KQ5fwVhhEVFZkMhlcRw3FRzMnw8jYGM8UjxD8GW+qSlQcktwKg4iI1CeEwE87g7Fu+Hgo7sTCyqYyPLasQ8/Z02BobCx1PCKdxQaIiEgDxN28jTVDxuCX/YcBAB3HjsD03VtQxcFe4mREuokNEBGRhshKz8ChL1Zh+/R5eU6Qbj2or9TRiHQOGyAiIg1z/ex5rOo/Erd+uQiTcmYYtHA+xq79EhYVrKSORqQz2AAREWmglMdPsMVjFo6sXIvszEw4dWqPOYd3w9GlhdTRiHQCGyAiIg0lhMC5Xfuwdvh4JEbHwLKyNSZ9vQ695nzCE6SJ3hIbICIiDRd/6y/4DR2Ln/e9vCl1B7fhmLF3K2zeqyltMCItxgaIiEgLZKVn4PCy1dg2bS6eJyXDrp4jZu3fAZfB/aSORqSV2AAREWmRP3+6gNUDRuHWzxEwNjPFwM/nYdy6lbB4p4LU0Yi0ChsgIiItk/L4CbZMno3Qr/yQnZmJhh3bYc6hXXB0aSl1NCKtwQaIiEgLCSFwfvd++A0bh8S/7/zvBOm16D1vBoxMTKSOR6Tx2AAREWmxhNvRWDN0HC7s/QYA0H7U0JcnSNdykDgZkWZjA0REpOWyMzIQssIXW6d4IuVJEqrVrYNZ+wLRZugAqaMRaSw2QEREOuLG+V+wesBI3Dj/C4zNTNH/0zlwX78a5Su+I3U0Io3DBoiISIc8f5KMrVM8EbLCF1kZGWjQvg3mHN6N+q5tpI5GpFHYABER6aALe7+B3zB3xN/+G/JKFTE+YDUGfD4PJuXMpI5GpBHYABER6ajEv6Kxdpg7ftyxFwDwweB+mH0gCO82rC9xMiLpsQEiItJh2ZmZOObjj43u0/A0UYHKNWvgk91fo8uksTAwNJQ6HpFk2AAREemBvyN/w+oBo3A57BQMjYzQY9pETN2xEZWq20kdjUgSbICIiPREmjIFu+ctxB4vb6SlPEfNJo0w+2AQWvbtKXU0ojLHBoiISM/8/t1J+AwYhb9//R1mFhYYsvRTuK1ZAYsKVlJHIyozbICIiPRQckIiNo3/BN/6rkd2VhYad+mAOYd3o26b1lJHIyoTbICIiPSUyM3F2cA9WDvMXXU/sYmb1qDfgtkwNjOVOh5RqWIDRESk5+Jv/YU1Q8fh3O79AIC2wwdh5r5A2NV3lDgZUelhA0RERMjOyMCRr/yweeIMPHv4CLa1HDB9z1Z0ch8FmQEPFaR7+K+aiIhUbodHYnX/kbhy8gcYGRvj45lTMHn7erxTzVbqaEQlig0QERHlkfpMiZ2enyL406VIf/ECtZo3xZxDu9G8Z3epoxGVGDZARESUr0tHv4fPwNGI+f0KzMpbYPgKb4xatRTlLC2ljkb01tgAERFRgZIexCNg7BR8v3YTcrKy0aR7F8w5vAt1WreQOhrRW2EDREREhRK5uTizNQjrRk7Aw5i7qGBTBR5b1qH33OkwMjGROh5RsbABIiKiInnw5034DnbDz/sOAQDajx6Gmfu2o6pjbYmTEamPDRARERVZVnoGDi9bja1TPKF8/ARV69TCzH3bebk8aR3+ayUiIrXdOP8LVvcfiaunf1RdLs+7y5M2YQNERETF8iL5KYJmLXh5ufzzF3Bo2hieh3ai9cA+UkcjeiM2QERE9FYuHf0eq/uPxN+Rv8HU3ByDvL3gvn415JUqSh2NqEBsgIiI6K29urv8kZVrkZWRgQbt22BuyB406tJB6mhE+WIDREREJUIIgXO79mHNkLF48OctWLxTAWPWrMCwZQthJi8vdTyiPNgAERFRiVJEx2DdiPE49XUgcnNy8H7vHphzaBdqt2wudTQiFTZARERU4nKys3Hc/2usd/PAo7v38U5VW0zeth595s2Ekamp1PGI2AAREVHpuXvlGnwHjcYv+w8DAFxHDcGs/YGo3qCuxMlI37EBIiKiUpWZlo5DX6zClsmz8OzhI9jWcsD03VvRZdJYGBgaSh2P9JSkDZCXlxciIyOhVCqhUCgQEhICR0fHNy43cOBA3LhxA2lpabh69Sp69OiR5/XAwEAIIfJUWFhYaW0GEREVwc0LEVjdfyT+OHEGhsZG6DFtIqbt3Axr+3eljkZ6SNIGqH379ggICEDr1q3RtWtXGBsb4+TJkzA3Ny9wGRcXFwQHB2Pbtm1o2rQpQkNDERoaioYNG+YZFxYWBltbW1UNGzastDeHiIjeIPWZErvmfIbd872RqlTCvnFDeH6zE22GDpA6GukZGQAhdYhXrK2t8ejRI7i6uuL8+fP5jtm3bx8sLCzQq1cv1XPh4eH4448/MHnyZAAvZ4AqVKiAfv36FenvNTExgek/TsqTy+WIi4uDpaUlUlJS3mKLiIioIFY2lTF06WdwdGkJALj1cwT2LVwO5cNHEicjbSWXy6FUKot0/Naoc4CsrKwAAElJSQWOcXFxwenTp/M8d+LECbi4uOR5rkOHDlAoFLh58yY2bNiAihUL/kXSBQsWQKlUqiouLu4ttoKIiIrimeIRvp40EyErfJCVnoG6bVpj7uHdaNK9i9TRSE8ITSiZTCaOHTsmzp8/X+i4jIwMMXTo0DzPTZ48WSQmJqoeDxkyRPTq1Us4OTmJPn36iOvXr4uLFy8KAwODfNdpYmIi5HK5qqpVqyaEEEIul0v+vrBYLJY+VBUHezEjeJvwiQoXPlHhYuRXi0U5S0vJc7G0q+RyuTrHb+kDAxAbNmwQMTExws7OrtBxRWmA/l0ODg5CCCE6depUGm8gi8VisUqgDIwMRTePcWLl5fPCJypcLDx9VNT9oJXkuVjaU+ocvzXiKzB/f3/07NkTHTt2fOPXT4mJibCxscnznI2NDRITEwtcJiYmBo8ePULt2rVLJC8REZW83OwcnNy0Hf4jJ+JhzF1Y2VTGxM1+GPDZXJiUKyd1PNIxkjdA/v7+6NevHzp16oTY2Ng3jg8PD0fnzp3zPNe1a1eEh4cXuIydnR0qVaqEhISEt41LRESl7P71G/Ad7IZzu/cDAD4Y0h9zDu/Ce82bSBuMdI5kU1UBAQEiOTlZuLq6ChsbG1WZmZmpxgQFBYnly5erHru4uIjMzEwxe/ZsUbduXeHt7S0yMjJEw4YNBQBhYWEhVq5cKVq1aiXs7e1Fp06dxKVLl8StW7eEiYlJiU+hsVgsFqv0qnbL5uLT44eFT1S4WHXlZ9FrzifCyNRU8lwszSytOQeoIG5ubqoxZ8+eFYGBgXmWGzhwoLh586ZIT08XUVFRokePHqrXzMzMxPHjx4VCoRAZGRkiJiZGbN68WVSpUqW03kAWi8VilWKZWpiLwYsWqE6QnnckWLzbsL7kuViaV+ocvzXqd4A0hTq/I0BERGWjfrsPMHjxAlhWtkZOdjZ+2LYLpzZtR052ttTRSENo7e8AERERFeTG+V+wqt8I/P79SRgaGaHrpLGYsXcbbOvUkjoaaSE2QEREpDVSnymxZ743gjw/xYvkp7Cr74hZ+wPRyX0Ub6xKamEDREREWufqyR+wst9wXDt7DkbGxvh45hRMDdrIG6tSkbEBIiIirfT8STICp89H8KdLkZbyHDWdG8Hzm51oO3wQZDKZ1PFIw7EBIiIirXbp6PdY3W8EbodHwqScGfotmI1JW9bhnWq2UkcjDcYGiIiItN5TxUNsnjgDB5euREZqGuq0eh9zDu1Gy369pI5GGooNEBER6YzwAyHwGTgad377A2blLTBkyX/gHrAalpWtpY5GGoYNEBER6ZQn9x9gw7ipOLpqHbIyMtDAtQ3mhuxB0x5dpY5GGoQNEBER6RyRm4ufdgZjzZCxuH/9BsytLDFy5RKM9lkGi3cqSB2PNAAbICIi0lmK6BisGzkBxwO2ICcrG87dOmFuyB407NBW6mgkMd4KIx+8FQYRke6xq++IYcsWour/fjn61yPfIfQrP6SnPJc4GZUU3gqDiIjoX+Ju3MaaIWPxw/ZdyM3NRYs+H2NuyB7UbdNa6mgkAc4A5YMzQEREuq2mcyMM/eIzVK5ZAwBw8dBRHF29DunPX0icjN4GZ4CIiIgKEXslCj6DRuOnXfuQm5uLVgN6Y27IHji6tJQ6GpURzgDlgzNARET6w6GZM4Yu/QzWNaoDAMIPhuLYan9kvEiVOBmpizNARERERRTz+xX4DByF83sOAABcBvbFnMO7Uad1C4mTUWniDFA+OANERKSfar3fFEOWfopK1e0AAL/sP4xvfQOQkcrZIG3AGSAiIqJiiL50Gav7j8KF4IMAgA+G9IfnoV2o1aKZxMmopHEGKB+cASIiototm2PIkk9R0a4qAOBC8EF8t2YDMtPSJE5GBeEMEBER0Vv6O/I3rO4/Er/sPwwAaDtsIOYc3oX33m8qcTIqCZwBygdngIiI6J/qtG6BwYsXoGK1l7NB53bvR9i6TchMS5c4Gf0TZ4CIiIhK0F8Rv2J1/5EIPxgKAHAdOQSeB3fBoZmztMGo2DgDlA/OABERUUHqftAKgxcvQAVbG+Tm5uL8ngMIW7cJWekZUkfTe5wBIiIiKiW3frmIVf1G4OLhYzAwMED7UUPh+c1O1HRuJHU0UgNngPLBGSAiIiqKem1bY/Ci/8DKpjJyc3Nxbuc+hK3/GtkZnA2SAmeAiIiIysDNCxFY2W84IkO/hYGBATqMGQ7Pb4JQo3FDqaPRG3AGKB+cASIiInXVd22DQd7zYVWlMnJzcvBTUDCOB2xBdmam1NH0BmeAiIiIytiNcz9jVb+RuHQsDAaGhug4biQ8D/LcIE3FGaB8cAaIiIjeRsMObTFw4XxYVrZ+eaXY7v0I89/MK8VKGWeAiIiIJHT9xwtY2XcEfj3y/csrxUYPg+fBXXiveROpo9H/cAYoH5wBIiKiklK/3QcY6D0fFWyqAAAu7P0G3/lt5D3FSgFngIiIiDTEjfO/YFXf4bh46CgAoO3wQZhzeBdqt2wucTL9xhmgfHAGiIiISoOjS0sMWuSluqfYL/sP41vfAGSkpkqcTDdwBoiIiEgD3Q6PzHOH+Q+G9MeckN1wdGkpcTL9wxmgfHAGiIiISlvtls0xePECVKpuBwC4eOgojq5eh/TnLyROpr04A0RERKTh/o78Dav7j8L5PQcAAK0G9Mbc0L2o185F4mT6gTNA+eAMEBERlSWHZs4YsuRTVLZ/FwDw65HvcWTlWqQplRIn0y6cASIiItIiMb9fgc/AUfgxaC9yc3PRos9HmBe6Bw07tpM6ms7iDFA+OANERERSsXd2wpAln8LmvZoAgN+/P4nQFb548fSZtMG0AGeAiIiItNTdK9fgO8gNP2zbidycHDT7qBvmhu5F464dpY6mUyRtgLy8vBAZGQmlUgmFQoGQkBA4Ojq+cbmBAwfixo0bSEtLw9WrV9GjR4/XxixevBjx8fFITU3FqVOnULt27dLYBCIiohKXnZmJ7/w2Yt2ICUj4KxryShXh5rsco32WoXzFd6SOpzOEVBUWFibc3NxEgwYNROPGjcW3334rYmNjhbm5eYHLuLi4iKysLDFnzhxRr149sWTJEpGRkSEaNmyoGjNv3jyRnJwsevfuLRo1aiRCQ0NFdHS0MDU1LVIuuVwuhBBCLpdL9t6wWCwWiwVAGBobi+7TJoqVl88Ln6hwseRcmGjao6vkuTSx1Dx+Sx/4VVlbWwshhGjXrl2BY/bt2yeOHTuW57nw8HCxceNG1eP4+Hjh6empemxpaSnS0tLEkCFDSuMNZLFYLBar1MuunqOY/U2Q8IkKFz5R4WLs2i+FZWVryXNpUqlz/Naoc4CsrKwAAElJSQWOcXFxwenTp/M8d+LECbi4vPzdBAcHB1StWjXPGKVSiYsXL6rG/JuJiQnkcnmeIiIi0iRxN29j7TB3nAjYgpysbDh1ao95oXvRsm9PqaNpJY1pgGQyGfz8/HDhwgVcv369wHG2trZQKBR5nlMoFLC1tVW9/uq5gsb824IFC6BUKlUVFxf3NptCRERUKnKys3Fy03b4DhmDe9f+RDlLOYYs/RSTvl6LinZVpY6nVTSmAQoICICTkxOGDh1a5n/3ihUrYGlpqSo7O7syz0BERFRUiX9Fw3/kRBxb7Y+s9Aw4urTEnMN70Hb4IMgMNObQrtE04l3y9/dHz5490bFjxzfOviQmJsLGxibPczY2NkhMTFS9/uq5gsb8W2ZmJlJSUvIUERGRJsvNycGPQXuxesBIRF+6DFPzcui3YDam7tiIKg72UsfTeJI3QP7+/ujXrx86deqE2NjYN44PDw9H586d8zzXtWtXhIeHAwBiYmKQkJCQZ4xcLkerVq1UY4iIiHTF43sPsHHcVBxcshLpz1/AoWljeB7cic7j3WBgZCh1PI0m2dnaAQEBIjk5Wbi6ugobGxtVmZmZqcYEBQWJ5cuXqx67uLiIzMxMMXv2bFG3bl3h7e2d72XwSUlJolevXsLJyUmEhITwMngWi8Vi6XxVsKkixm/wUV0pNvtAkLCr5yh5rrIqrbkMviBubm6qMWfPnhWBgYF5lhs4cKC4efOmSE9PF1FRUaJHjx6vrXvx4sUiISFBpKWliVOnTok6deqU1hvIYrFYLJZGVbOeH4ol548Ln6hwsfLyedFjuocwMjGRPFdplzrHb94LLB+8FxgREWm78hXfQb8Fs9GkexcAwMOYu9i/cDli/7gqcbLSo87xmw1QPtgAERGRrnDq5IoBn82FZWVr5Obm4ufgg/h+7SZkpqVJHa3E8WaoREREBAC49sM5rOw7HBcPH4OBgQHajRiMuSF74OjSUupokuIMUD44A0RERLrI0aUFBi70QqXq1QAAkaHf4uiqdUhT6saxjjNARERE9Jrb4b9idf+ROLd7P3Jzc9Gyb0/MC90Lp07tpY5W5jgDlA/OABERka6r2aQxBi9eAJv3agIA/jhxBiErfPD8SbK0wd4CZ4CIiIioULF/XIXvIDec/noHcrKz0eTDzpgXGozmPbtLHa1McAYoH5wBIiIifWJXzxFDlnwKu/qOAIAb53/BwSUr8TRR8YYlNQtngIiIiKjI4m7eht/wcfjObyOyMjJQv90HmBu6B22GDYRMJpM6XqngDFA+OANERET6qoqDPQYvWgCHZs4AgNg/onDAezkUd2KlDVYE/CHEt8QGiIiI9JlMJkPrQX3Rc9ZUmJW3QHZWFs58vQNntu1CTlaW1PEKxK/AiIiIqNiEEAg/EIJVfYfj+o8XYGRsjA+nTsDsAztg7+wkdbwSwRmgfHAGiIiI6P+cP+yMfgtmQ16poup2GmHrNiMjNVXqaHlwBoiIiIhKzJUTZ/BV72GIDP32/7fTCN2Deu1cpI5WbJwBygdngIiIiPJXp3ULDPKej0rV7QAAv39/EqFfrsGL5KfSBgNngIiIiKiU/BXx8nYaZwP3IDcnB80+6ob5R7TvBxQ5A5QPzgARERG9WfUG9TB48QLY1Xv5A4q3fo7AN0u+QnJ8oiR5OANEREREpe7BnzfhN+z/P6BYt01rzA3Zi3Yjh0BmoNktBmeA8sEZICIiIvVY27+LwYsWoNb7TQEA96L+xIFFy5FwO7rMMvCHEN8SGyAiIiL1yWQytBrQGz1nT0M5eXnkZGXjh8BdOL15B7IzM0v97+dXYERERFTmhBCIOHgEK/sMQ9SZn2BobISuE8fC8+BO1a01NAVngPLBGSAiIqK316hze/T/dA4sK1sDAH7edwjf+W1AxovS+QFFzgARERGR5KLO/ISVfYcj4uARAECboQMw70gwGnZoK3EyzgDlizNAREREJatWi2YY5O2FyvbvAng5G3R42eoS/Ts4A0REREQaJfrX37F6wCj8sG0ncrKzEfP7FUnzcAYoH5wBIiIiKj3WNarj8b0HJb5ezgARERGRxiqN5kddbICIiIhI77ABIiIiIr3DBoiIiIj0DhsgIiIi0jtsgIiIiEjvsAEiIiIivcMGiIiIiPQOGyAiIiLSO2yAiIiISO+wASIiIiK9wwaIiIiI9A4bICIiItI7bICIiIhI7xhJHUCTyeVyqSMQERFREalz3GYDlI9Xb2BcXJzESYiIiEhdcrkcKSkphY6RARBlE0e7VKtW7Y1vXnHI5XLExcXBzs6uVNavSbitukuftpfbqrv0aXv1bVvj4+PfOI4zQAUoypv3NlJSUnT+H+Er3FbdpU/by23VXfq0vfqwrUXdPp4ETURERHqHDRARERHpHTZAZSwjIwOLFi1CRkaG1FFKHbdVd+nT9nJbdZc+ba8+bWtR8SRoIiIi0jucASIiIiK9wwaIiIiI9A4bICIiItI7bICIiIhI77ABKgVTpkxBTEwM0tLSEBERgRYtWhQ6fuDAgbhx4wbS0tJw9epV9OjRo4ySFp+XlxciIyOhVCqhUCgQEhICR0fHQpdxc3ODECJPpaWllVHi4vP29n4t940bNwpdRhv36SsxMTGvba8QAuvXr893vDbt13bt2uHo0aOIi4uDEAJ9+vR5bczixYsRHx+P1NRUnDp1CrVr137jetX9zJeFwrbVyMgIX375Ja5evYrnz58jLi4OQUFBqFq1aqHrLM5noay8ad8GBga+lj0sLOyN69W2fQsg38+vEAJz5swpcJ2avG9LCxugEjZ48GD4+vpi8eLFaNasGa5cuYITJ06gcuXK+Y53cXFBcHAwtm3bhqZNmyI0NBShoaFo2LBhGSdXT/v27REQEIDWrVuja9euMDY2xsmTJ2Fubl7ocs+ePYOtra2q7O3tyyjx27l27Vqe3G3bti1wrLbu01datGiRZ1u7dOkCAPjmm28KXEZb9quFhQWuXLmCqVOn5vv6vHnzMH36dHh4eKBVq1Z48eIFTpw4AVNT0wLXqe5nvqwUtq3m5uZo1qwZli5dimbNmqF///6oW7cujh49+sb1qvNZKEtv2rcAEBYWlif7sGHDCl2nNu5bAHm20dbWFmPHjkVubi4OHTpU6Ho1dd+WJsEquYqIiBD+/v6qxzKZTDx48EDMnz8/3/H79u0Tx44dy/NceHi42Lhxo+Tbok5ZW1sLIYRo165dgWPc3NxEcnKy5FnVLW9vb3H58uUij9eVffqq1qxZI/766y+d269CCNGnT588z8XHxwtPT0/VY0tLS5GWliaGDBlS4HrU/cxryrb+u95//30hhBDvvvtugWPU/Sxo0vYGBgaKkJAQtdajK/s2JCREnD59utAx2rJvS7I4A1SCjI2N0bx5c5w+fVr1nBACp0+fhouLS77LuLi45BkPACdOnChwvKaysrICACQlJRU6rnz58oiNjcW9e/cQGhqKBg0alEW8t1anTh3ExcUhOjoau3fvxrvvvlvgWF3Zp8DLf9MjR47E9u3bCx2nrfv1nxwcHFC1atU8+06pVOLixYsF7rvifOY1lZWVFXJzc/H06dNCx6nzWdA0HTp0gEKhwM2bN7FhwwZUrFixwLG6sm+rVKmCjz/+GNu2bXvjWG3et8XBBqgEWVtbw8jICAqFIs/zCoUCtra2+S5ja2ur1nhNJJPJ4OfnhwsXLuD69esFjrt16xbGjRuHPn36YOTIkTAwMMAvv/wCOzu7MkyrvosXL2LMmDHo3r07Jk+eDAcHB5w/fx7ly5fPd7wu7NNX+vbtiwoVKmDHjh0FjtHW/fpvr/aPOvuuOJ95TWRqaoqvvvoKwcHBhd5IUt3PgiY5fvw4Ro8ejc6dO2P+/Plo3749wsLCYGCQ/2FQV/atm5sbUlJScPjw4ULHafO+LS7eDZ7eWkBAAJycnN74fXFERAQiIiJUj3/55RfcuHEDkyZNwsKFC0s7ZrEdP35c9eeoqChcvHgRd+/exeDBg984M6Lt3N3dERYWhoSEhALHaOt+pZeMjIxw4MAByGQyTJ48udCx2vxZ2L9/v+rP165dw9WrV3Hnzh106NABP/zwg4TJSte4ceOwZ8+eN94CQ5v3bXFxBqgEPX78GNnZ2bCxscnzvI2NDRITE/NdJjExUa3xmsbf3x89e/ZEx44dERcXp9ay2dnZuHz5cpGustEkz549w+3btwvMre379JUaNWqgS5cu2Lp1q1rLaet+fbV/1Nl3xfnMa5JXzY+9vT26du1a6OxPft70WdBkMTExePToUYHZtX3fAkDbtm1Rr149tT/DgHbv26JiA1SCsrKy8Ntvv6Fz586q52QyGTp37ozw8PB8lwkPD88zHgC6du1a4HhN4u/vj379+qFTp06IjY1Ve3kDAwM0atSo0NkFTWRhYYFatWoVmFub9+k/jR07Fg8fPsR3332n1nLaul9jYmKQkJCQZ9/J5XK0atWqwH1XnM+8pnjV/NSpUwddunR54/l7+XnTZ0GT2dnZoVKlSgVm1+Z9+4q7uzsuXbqEq1evqr2sNu9bdUh+JrYu1eDBg0VaWpoYPXq0qFevnti0aZNISkoSVapUEQBEUFCQWL58uWq8i4uLyMzMFLNnzxZ169YV3t7eIiMjQzRs2FDybSmsAgICRHJysnB1dRU2NjaqMjMzU43597Z+/vnnomvXrsLBwUE0bdpU7N27V6Smpor69etLvj2F1apVq4Srq6uwt7cXLi4u4uTJk+Lhw4fC2tpap/bpP0smk4nY2FixYsWK117T5v1qYWEhnJ2dhbOzsxBCiJkzZwpnZ2fVlU/z5s0TSUlJolevXsLJyUmEhISI6OhoYWpqqlrH6dOnxdSpU1WP3/SZ18RtNTIyEqGhoeLevXuicePGeT7DxsbGBW7rmz4Lmrq9FhYWYuXKlaJVq1bC3t5edOrUSVy6dEncunVLmJiY6NS+fTVGLpeL58+fi0mTJuW7Dm3at6VYkgfQuZo6daqIjY0V6enpIiIiQrRs2VL12tmzZ0VgYGCe8QMHDhQ3b94U6enpIioqSvTo0UPybXhTFcTNza3AbfX19VW9LwkJCeLbb78VTZo0kXxb3lTBwcEiLi5OpKeni/v374vg4GDx3nvv6dw+/Wd17dpVCCFEnTp1XntNm/dr+/bt8/13+8/tWbx4sUhISBBpaWni1KlTr70HMTExwtvbO89zhX3mNXFb7e3tC/wMt2/fvsBtfdNnQVO318zMTBw/flwoFAqRkZEhYmJixObNm19rZHRh374aM2HCBPHixQthaWmZ7zq0ad+WVsn+9wciIiIivcFzgIiIiEjvsAEiIiIivcMGiIiIiPQOGyAiIiLSO2yAiIiISO+wASIiIiK9wwaIiIiI9A4bICIiItI7bICIiIpACIE+ffpIHYOISggbICLSeIGBgRBCvFZhYWFSRyMiLWUkdQAioqIICwvD2LFj8zyXkZEhURoi0nacASIirZCRkQGFQpGnnj59CuDl11MeHh74/vvvkZqaiujoaAwYMCDP8k5OTjhz5gxSU1Px+PFjbN68GRYWFnnGjB07FteuXUN6ejri4+Ph7++f53Vra2scPnwYL168wO3bt9GrV69S3WYiKl2S35GVxWKxCqvAwEAREhJS4OtCCPHo0SPh7u4u6tSpI5YsWSKysrJEvXr1BABhbm4u4uLixMGDB0XDhg1Fx44dRXR0dJ67Z3t4eIjU1FQxffp0UadOHfH++++LGTNm5Pk77t27J4YOHSpq1aol/Pz8hFKpFO+8847k7w+LxSpWSR6AxWKxCq3AwECRlZUlUlJS8tSCBQsE8LI52bBhQ55lwsPDRUBAgAAgxo8fL548eSLMzc1Vr/fo0UNkZ2eLKlWqCADiwYMHYunSpQVmEEKIJUuWqB6bm5sLIYT48MMPJX9/WCyW+sVzgIhIK5w9exaTJ0/O81xSUpLqz+Hh4XleCw8PR5MmTQAA9evXx5UrV5Camqp6/eeff4ahoSHq1q0LIQTs7Oxw5syZQjNcvXpV9efU1FQ8e/YMVapUKe4mEZGE2AARkVZ48eIFoqOjS2XdaWlpRRqXlZWV57EQAgYGPJWSSBvxk0tEOqF169avPb5x4wYA4MaNG3B2doa5ubnq9TZt2iAnJwe3bt3C8+fPERMTg86dO5dpZiKSDmeAiEgrmJqawsbGJs9z2dnZePLkCQBg0KBBuHTpEi5cuIARI0agZcuWcHd3BwDs2bMHixcvRlBQEBYtWoTKlSvD398fu3btwsOHDwEAixYtwqZNm/Dw4UOEhYVBLpejTZs2WL9+fdluKBGVGclPRGKxWKzCKjAwUOTnxo0bAnh5gvLkyZPFiRMnRFpamrhz544YNGhQnnU4OTmJM2fOiNTUVPH48WOxefNmYWFhkWfMxIkTxY0bN0RGRoaIi4sTa9euVb0mhBB9+vTJMz45OVm4ublJ/v6wWCz1S/a/PxARaS0hBPr27YsjR45IHYWItATPASIiIiK9wwaIiIiI9A6/AiMiIiK9wxkgIiIi0jtsgIiIiEjvsAEiIiIivcMGiIiIiPQOGyAiIiLSO2yAiIiISO+wASIiIiK9wwaIiIiI9M5/AW8LX0iXyqfgAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Plot training loss as a function of epoch:\n",
        "plt.plot(loss_epoch)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "d7AEbmpcKcPY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9 0 1 ... 9 0 0]\n",
            "[7 2 1 ... 4 5 6]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.4146"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Accuracy on test set\n",
        "dlayer.forward(X_test)\n",
        "softmax.forward(dlayer.output)\n",
        "ypred = np.argmax(softmax.output.T, axis = 1)\n",
        "print(ypred)\n",
        "ytrue = np.argmax(Y_test.T, axis = 1)\n",
        "print(ytrue)\n",
        "np.mean(ytrue == ypred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
